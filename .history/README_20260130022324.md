# Error Bar Detection in Scientific Charts

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.8+-blue?logo=python&logoColor=white" alt="Python">
  <img src="https://img.shields.io/badge/PyTorch-2.0+-ee4c2c?logo=pytorch&logoColor=white" alt="PyTorch">
  <img src="https://img.shields.io/badge/OpenCV-4.8+-5C3EE8?logo=opencv&logoColor=white" alt="OpenCV">
  <img src="https://img.shields.io/badge/HuggingFace-Transformers-yellow?logo=huggingface&logoColor=white" alt="HuggingFace">
  <img src="https://img.shields.io/badge/Platform-Kaggle-20BEFF?logo=kaggle&logoColor=white" alt="Kaggle">
</p>

<p align="center">
  <strong>Automatic detection and measurement of error bars in scientific plot images using Computer Vision and Vision-Language Models</strong>
</p>

---

## Table of Contents

- [Overview](#overview)
- [Project Structure](#project-structure)
- [Methodology](#methodology)
  - [Pipeline 1: CV + ROI with ML Refinement](#pipeline-1-cv--roi-with-ml-refinement)
  - [Pipeline 2: Vision-Language Model Approach](#pipeline-2-vision-language-model-approach)
- [Results Summary](#results-summary)
- [Detailed Results](#detailed-results)
- [Running on Kaggle Free Tier GPU](#running-on-kaggle-free-tier-gpu)
- [Dataset Format](#dataset-format)
- [Output Format](#output-format)
- [Model Artifacts](#model-artifacts)
- [References](#references)

---

## Overview

This project addresses the challenge of automatically detecting and measuring error bars in scientific chart images. Given an input image and data point coordinates, the system outputs the pixel distances from each data point to its corresponding upper and lower error bar endpoints.

### Task Definition

| Component | Description |
|-----------|-------------|
| **Input** | Scientific plot image (PNG/JPG) + Data point coordinates (x, y) in pixel space |
| **Output** | `topBarPixelDistance`: Pixels from data point to upper error bar endpoint |
|  | `bottomBarPixelDistance`: Pixels from data point to lower error bar endpoint |

### Key Challenges

- Variable plot styles, colors, and resolutions
- Overlapping error bars and dense data points
- Distinguishing error bars from grid lines and other visual elements
- Handling missing or asymmetric error bars

---

## Project Structure

```
Error-Bar-Detection-Project/
|
|-- README.md                                          # This documentation
|-- figure 1.png                                       # Pipeline 1 architecture diagram
|-- figure 2.png                                       # Pipeline 2 architecture diagram
|
|-- Basic OpenCV + ROI/
|   |-- OpenCV + ROI.ipynb                             # Basic CV-only approach notebook
|   |-- Results/
|       |-- summary_metrics.csv                        # Aggregate performance metrics
|       |-- per_image_metrics.csv                      # Per-image detailed metrics
|       |-- error_distributions.png                    # Error distribution visualization
|       |-- predictions/                               # Individual JSON predictions
|
|-- OpenCV + ROI (Geometry-Based Deterministic Pipeline) + ML Refinement/
|   |-- cv-ml-hybrid-errorbar-detection-new.ipynb      # Hybrid CV+ML pipeline notebook
|   |-- Results/
|       |-- final_model_comparison_600samples.csv      # Model comparison results
|       |-- ablation_study.csv                         # Ablation study results
|       |-- improvement_over_baseline_600samples.csv   # Improvement analysis
|       |-- feature_descriptions.csv                   # ML feature documentation
|       |-- hybrid_features_dataset.csv                # Extracted features dataset
|       |-- predictions/                               # Individual JSON predictions
|
|-- Zero shot QWEN2.5-VL-7B base & finetuned/
|   |-- Zero shot QWEN2.5-VL-7B inference.ipynb        # Base model inference notebook
|   |-- qwen2-5-vl-error-bar-detection-fine-tuning.ipynb  # Fine-tuning notebook
|   |-- Chartqwen inference.ipynb                      # Fine-tuned model inference
|   |-- Results of base QWEN2.5-VL-7B-INSTRUCT/
|   |   |-- qwen_vqa_summary_metrics.csv               # Base model metrics
|   |   |-- qwen_vqa_per_image_metrics.csv             # Base model per-image results
|   |   |-- predictions/                               # Base model predictions
|   |-- Results of Chartqwen/                          # Fine-tuned model results
```

---

## Methodology

This project implements two distinct pipelines for error bar detection, each with different trade-offs between speed, accuracy, and computational requirements.

---

### Pipeline 1: CV + ROI with ML Refinement

<p align="center">
  <img src="figure 1.png" alt="Pipeline 1 Architecture" width="400">
</p>
<p align="center"><em>Figure 1: Computer Vision + Machine Learning Hybrid Pipeline Architecture</em></p>

#### Architecture Overview

```
Input Image + Coordinates --> ROI Extraction --> Edge Detection --> Vertical Line Analysis
                                   |                   |                    |
                                   v                   v                    v
                            Feature Extraction   Canny Edges         Line Projection
                                   |                   |                    |
                                   +-------------------+--------------------+
                                                       |
                                                       v
                                              CV Coarse Estimate
                                                       |
                                                       v
                                              ML Refinement (MLP)
                                                       |
                                                       v
                                              Final Prediction
```

#### Stage 1: Computer Vision Baseline

The CV stage performs geometric analysis using classical image processing techniques:

| Step | Operation | Parameters |
|------|-----------|------------|
| 1 | ROI Extraction | 30px width x 150px height around data point |
| 2 | Grayscale Conversion | BGR to single channel |
| 3 | Edge Detection | Canny with thresholds (50, 150) |
| 4 | Vertical Line Detection | Min length 5px, tolerance 3px |
| 5 | Distance Calculation | Geometric measurement to endpoints |

**CV Parameters:**
```python
ROI_WIDTH = 30          # Horizontal search region
ROI_HEIGHT = 150        # Vertical search region
EDGE_THRESHOLD1 = 50    # Canny lower threshold
EDGE_THRESHOLD2 = 150   # Canny upper threshold
MIN_LINE_LENGTH = 5     # Minimum error bar segment
VERTICAL_TOLERANCE = 3  # Max x-axis deviation
```

#### Stage 2: ML Refinement

The ML stage learns to correct systematic CV errors using extracted features:

**Feature Categories (14 total):**

| Category | Features | Description |
|----------|----------|-------------|
| ROI Intensity | `roi_mean_intensity`, `roi_std_intensity`, `roi_min_intensity`, `roi_max_intensity` | Pixel brightness statistics |
| ROI Gradients | `roi_grad_y_mean`, `roi_grad_y_std` | Vertical gradient strength |
| ROI Edges | `roi_edge_density` | Percentage of edge pixels |
| ROI Center | `roi_center_col_mean`, `roi_center_col_std`, `roi_center_col_min`, `roi_center_col_max` | Center column statistics |
| CV Coarse | `cv_coarse_top_dist`, `cv_coarse_bottom_dist`, `cv_confidence` | CV detection outputs |

**ML Models Evaluated:**

| Model | Architecture | Hyperparameters |
|-------|--------------|-----------------|
| Linear Regression | Single layer | Default |
| Ridge Regression | L2 regularized | alpha=1.0 |
| MLP | 3 hidden layers | (64, 32, 16), ReLU |
| Tuned MLP | Grid-searched MLP | Optimized hidden sizes |
| Random Forest | Ensemble trees | 100 estimators, max_depth=10 |
| Gradient Boosting | Sequential trees | 100 estimators, lr=0.1 |

#### Why Hybrid Approach?

| Pure CV Limitations | Pure ML Limitations | Hybrid Advantages |
|---------------------|---------------------|-------------------|
| Fixed thresholds fail on varied styles | Requires massive labeled data | CV provides geometric structure |
| Noise sensitive edge detection | Black box predictions | ML refines CV errors |
| Cannot adapt to dataset patterns | Overfits to artifacts | Data efficient training |
| No learning capability | No geometric understanding | Explainable pipeline |

---

### Pipeline 2: Vision-Language Model Approach

<p align="center">
  <img src="figure 2.png" alt="Pipeline 2 Architecture" width="800">
</p>
<p align="center"><em>Figure 2: Vision-Language Model (VLM) Pipeline Architecture</em></p>

#### Architecture Overview

```
Input Image + Coordinates --> Image Encoder --> Vision Tokens
                                                     |
                                                     v
User Prompt (with coordinates) --> Tokenizer --> Text Tokens
                                                     |
                                                     +-----> Multimodal Fusion
                                                                  |
                                                                  v
                                                     Language Model Decoder
                                                                  |
                                                                  v
                                                     JSON Output Parser
                                                                  |
                                                                  v
                                                     Pixel Measurements
```

#### Model Configuration

**Base Model: Qwen2.5-VL-7B-Instruct**

| Specification | Value |
|--------------|-------|
| Architecture | Vision-Language Transformer |
| Parameters | 7 Billion |
| Vision Encoder | ViT-based |
| Context Length | 32K tokens |
| Image Resolution | Dynamic (up to 768px) |

**Zero-Shot Configuration:**

```python
MODEL_NAME = "Qwen/Qwen2.5-VL-7B-Instruct"
MAX_NEW_TOKENS = 1024
TEMPERATURE = 0.1
IMAGE_MAX_SIZE = 768
PRECISION = "float16"  # FP16 for T4 GPU
```

#### Fine-tuning: Chartqwen

The base model is fine-tuned using LoRA (Low-Rank Adaptation) for task-specific performance:

**LoRA Configuration:**

| Parameter | Value | Description |
|-----------|-------|-------------|
| Rank (r) | 32 | Low-rank decomposition dimension |
| Alpha | 64 | Scaling factor |
| Dropout | 0.05 | Regularization |
| Target Modules | q_proj, k_proj, v_proj, o_proj | Attention layers |

**Training Configuration:**

| Parameter | Value |
|-----------|-------|
| Training Samples | 600 |
| Epochs | 1 |
| Batch Size | 1 |
| Gradient Accumulation | 16 |
| Effective Batch Size | 16 |
| Learning Rate | 2e-4 |
| Warmup Ratio | 0.03 |
| Max Gradient Norm | 1.0 |

**Published Model:**
- HuggingFace Hub: [`Sayeem26s/Chartqwen`](https://huggingface.co/Sayeem26s/Chartqwen)

#### Prompt Engineering

**System Prompt:**
```
You are a precise error bar detection system for scientific plots.
Given an image of a scientific plot and data point coordinates, detect the error bars.
For each point, output the pixel distance from the data point to the top and bottom of the error bar.
If no error bar exists for a point, output 0 for both distances.
```

**User Prompt Template:**
```
Analyze this scientific plot image and detect error bars for the following data points:

[{"x": 96.6, "y": 70.9}, {"x": 120.3, "y": 85.2}, ...]

For each point, measure:
- topBarPixelDistance: pixel distance from data point to top of error bar (0 if none)
- bottomBarPixelDistance: pixel distance from data point to bottom of error bar (0 if none)

Output as JSON array:
[
  {"x": <x>, "y": <y>, "topBarPixelDistance": <top>, "bottomBarPixelDistance": <bottom>}
]
```

---

## Results Summary

### Comparative Performance (600 Test Images, 10,229 Data Points)

| Rank | Approach | Mean Error (px) | RMSE (px) | Acc@5px (%) | Acc@10px (%) | Acc@20px (%) |
|:----:|----------|:---------------:|:---------:|:-----------:|:------------:|:------------:|
| 1 | **CV Only (Baseline)** | **21.07** | **37.74** | 0.5 | **10.5** | **72.7** |
| 2 | MLP Refinement | 23.93 | 36.36 | 0.0 | 2.7 | 52.3 |
| 3 | Tuned MLP | 24.04 | 36.26 | 0.1 | 2.3 | 51.0 |
| 4 | Linear Regression | 24.79 | 36.70 | 0.1 | 1.0 | 44.2 |
| 5 | Ridge Regression | 24.79 | 36.70 | 0.1 | 1.0 | 44.2 |
| 6 | Gradient Boosting | 27.67 | 56.71 | 0.1 | 6.3 | 65.3 |
| 7 | Random Forest | 30.26 | 70.28 | 0.4 | 8.9 | 67.0 |
| 8 | Basic CV + ROI | 34.38 | 52.50 | **16.84** | 29.35 | 44.27 |
| 9 | Qwen2.5-VL (Zero-shot) | 40.22 | 67.77 | 17.50 | 27.18 | 44.09 |

### Key Findings

| Finding | Observation |
|---------|-------------|
| Best Overall Accuracy | CV Only achieves lowest mean error (21.07px) and highest Acc@20px (72.7%) |
| ML Refinement | Does not improve over CV baseline; increases error by 13-44% |
| VLM Zero-shot | Comparable to Basic CV but slower; 40.22px mean error |
| Fine-tuning Impact | Chartqwen expected to improve over base Qwen2.5-VL |
| Speed vs Accuracy | CV pipeline 100x faster than VLM approach |

---

## Detailed Results

### Pipeline 1: CV + ML Hybrid Results

#### Baseline vs Refinement Comparison

| Approach | Mean Error (px) | Baseline (px) | Improvement (%) | Error Reduction (px) |
|----------|:---------------:|:-------------:|:---------------:|:--------------------:|
| CV Only (Baseline) | 21.07 | - | - | - |
| MLP | 23.93 | 21.07 | -13.5 | -2.85 |
| Tuned MLP | 24.04 | 21.07 | -14.1 | -2.96 |
| Ridge Regression | 24.79 | 21.07 | -17.7 | -3.72 |
| Linear Regression | 24.79 | 21.07 | -17.7 | -3.72 |
| Gradient Boosting | 27.67 | 21.07 | -31.3 | -6.59 |
| Random Forest | 30.26 | 21.07 | -43.6 | -9.18 |

#### Ablation Study

| Method | MAE Top (px) | MAE Bottom (px) | MAE Avg (px) | RMSE Avg (px) |
|--------|:------------:|:---------------:|:------------:|:-------------:|
| CV Only | 29.34 | 27.12 | 28.23 | 223.50 |
| ML Only (no CV) | 32.66 | 32.06 | 32.36 | 183.59 |
| Hybrid (CV + MLP) | 31.49 | 28.77 | 30.13 | 221.87 |

### Pipeline 2: VLM Results

#### Qwen2.5-VL Zero-Shot Performance

| Metric | Value |
|--------|:-----:|
| Total Images | 600 |
| Total Points | 10,229 |
| Mean Top Error | 42.40 px |
| Mean Bottom Error | 38.04 px |
| Mean Overall Error | 40.22 px |
| RMSE | 67.77 px |
| Accuracy @ 5px | 17.50% |
| Accuracy @ 10px | 27.18% |
| Accuracy @ 20px | 44.09% |

### Basic CV + ROI Results

| Metric | Value |
|--------|:-----:|
| Total Images | 600 |
| Total Points | 10,229 |
| Mean Top Error | 34.81 px |
| Mean Bottom Error | 33.95 px |
| Mean Overall Error | 34.38 px |
| Median Overall Error | 24.99 px |
| RMSE | 52.50 px |
| Accuracy @ 5px | 16.84% |
| Accuracy @ 10px | 29.35% |
| Accuracy @ 20px | 44.27% |

---

## Running on Kaggle Free Tier GPU

### Prerequisites

- Kaggle account (free)
- GPU quota available (30 hours/week on free tier)
- Dataset uploaded to Kaggle: `graph-plots`

### Hardware Specifications (Kaggle Free Tier)

| Component | Specification |
|-----------|---------------|
| GPU | NVIDIA Tesla T4 |
| VRAM | 16 GB |
| System RAM | 13 GB |
| Disk | 73 GB |
| Weekly Quota | 30 GPU hours |

---

### Running Pipeline 1: CV + ROI + ML Refinement

#### Step 1: Create New Kaggle Notebook

1. Navigate to [kaggle.com/code](https://www.kaggle.com/code)
2. Click **"+ New Notebook"**
3. In **Settings** (right sidebar):
   - Accelerator: **None** (CPU sufficient for CV pipeline)
   - Internet: **On**

#### Step 2: Add Dataset

1. Click **"+ Add data"** in right sidebar
2. Search for `graph-plots`
3. Click **"Add"** to attach dataset

#### Step 3: Upload Notebook

1. Click **"File"** > **"Import Notebook"**
2. Select one of:
   - `Basic OpenCV + ROI/OpenCV + ROI.ipynb`
   - `OpenCV + ROI (Geometry-Based Deterministic Pipeline) + ML Refinement/cv-ml-hybrid-errorbar-detection-new.ipynb`

#### Step 4: Run All Cells

1. Click **"Run All"** or press `Ctrl+Shift+Enter`
2. Expected runtime: **5-15 minutes** (CPU)

#### Expected Output Files

```
/kaggle/working/
|-- per_image_metrics.csv
|-- summary_metrics.csv
|-- predictions/
    |-- *.json (600 files)
```

---

### Running Pipeline 2: VLM Approach

#### Option A: Zero-Shot Inference (Base Model)

##### Step 1: Create New Kaggle Notebook

1. Navigate to [kaggle.com/code](https://www.kaggle.com/code)
2. Click **"+ New Notebook"**
3. In **Settings** (right sidebar):
   - Accelerator: **GPU T4 x2**
   - Internet: **On** (required for model download)

##### Step 2: Add Dataset

1. Click **"+ Add data"** in right sidebar
2. Search for `graph-plots`
3. Click **"Add"** to attach dataset

##### Step 3: Upload Notebook

1. Click **"File"** > **"Import Notebook"**
2. Select: `Zero shot QWEN2.5-VL-7B base & finetuned/Zero shot QWEN2.5-VL-7B inference.ipynb`

##### Step 4: Run All Cells

1. Click **"Run All"** or press `Ctrl+Shift+Enter`
2. Expected runtime: **30-60 minutes** for 600 images
3. GPU quota usage: ~0.5-1.0 hours

#### Option B: Fine-tuned Model Inference (Chartqwen)

##### Step 1: Create New Kaggle Notebook

1. Navigate to [kaggle.com/code](https://www.kaggle.com/code)
2. Click **"+ New Notebook"**
3. In **Settings** (right sidebar):
   - Accelerator: **GPU T4 x2**
   - Internet: **On** (required for model download)

##### Step 2: Add Dataset

1. Click **"+ Add data"** in right sidebar
2. Search for `graph-plots`
3. Click **"Add"** to attach dataset

##### Step 3: Upload Notebook

1. Click **"File"** > **"Import Notebook"**
2. Select: `Zero shot QWEN2.5-VL-7B base & finetuned/Chartqwen inference.ipynb`

##### Step 4: Run All Cells

1. Click **"Run All"** or press `Ctrl+Shift+Enter`
2. Expected runtime: **1-3 minutes** for 100 images (optimized)
3. GPU quota usage: ~0.03-0.05 hours

#### Option C: Fine-tuning (Training Chartqwen)

> **Note:** Fine-tuning requires approximately 1-1.5 hours of GPU time.

##### Step 1: Create New Kaggle Notebook

1. Navigate to [kaggle.com/code](https://www.kaggle.com/code)
2. Click **"+ New Notebook"**
3. In **Settings** (right sidebar):
   - Accelerator: **GPU T4 x2**
   - Internet: **On**

##### Step 2: Add Dataset

1. Click **"+ Add data"** in right sidebar
2. Search for `graph-plots`
3. Click **"Add"** to attach dataset

##### Step 3: Add HuggingFace Token Secret

1. In **Settings**, scroll to **"Secrets"**
2. Click **"Add a new secret"**
3. Name: `HF_TOKEN`
4. Value: Your HuggingFace write token from [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)

##### Step 4: Upload and Run Notebook

1. Click **"File"** > **"Import Notebook"**
2. Select: `Zero shot QWEN2.5-VL-7B base & finetuned/qwen2-5-vl-error-bar-detection-fine-tuning.ipynb`
3. Run all cells
4. Model will be uploaded to HuggingFace Hub upon completion

---

### GPU Memory Optimization Tips

For VLM pipelines on Kaggle T4 GPU (16GB VRAM):

| Optimization | Setting | Impact |
|--------------|---------|--------|
| Precision | FP16 (float16) | 50% memory reduction |
| Image Size | 512px max | 40% faster processing |
| Max Tokens | 512 | 50% faster generation |
| Memory Clearing | Every 10 images | Prevents OOM errors |
| Batch Size | 1 | VLMs require small batches |

**Optimized Configuration (Chartqwen inference):**

```python
IMAGE_MAX_SIZE = 512      # Aggressive reduction for T4
MAX_NEW_TOKENS = 512      # Minimal tokens for speed
TEMPERATURE = 0.0         # Deterministic outputs
torch_dtype = torch.float16  # FP16 precision
```

---

### Troubleshooting

| Issue | Solution |
|-------|----------|
| CUDA Out of Memory | Reduce `IMAGE_MAX_SIZE` to 384 or 256 |
| Model Download Fails | Enable Internet in notebook settings |
| Slow Inference | Ensure GPU accelerator is selected |
| Import Errors | Run pip install cell first |
| Dataset Not Found | Verify dataset is attached to notebook |

---

## Dataset Format

### Input Labels (test_labels/)

```json
{
  "image_file": "00271e61-86e3-453f-8101-fe906ae927eb.png",
  "data_points": [
    {
      "lineName": "Line 1",
      "points": [
        {"x": 96.6, "y": 70.9},
        {"x": 120.3, "y": 85.2}
      ]
    }
  ]
}
```

### Ground Truth Labels (labels/)

```json
[
  {
    "lineName": "Line 1",
    "points": [
      {
        "x": 96.6,
        "y": 70.9,
        "label": "",
        "topBarPixelDistance": 15.5,
        "bottomBarPixelDistance": 15.5,
        "deviationPixelDistance": 15.5
      }
    ]
  }
]
```

---

## Output Format

### Prediction JSON

```json
{
  "image_file": "00271e61-86e3-453f-8101-fe906ae927eb.png",
  "model": "Chartqwen",
  "error_bars": [
    {
      "lineName": "",
      "points": [
        {
          "data_point": {"x": 96.6, "y": 70.9},
          "upper_error_bar": {"x": 96.6, "y": 55.4},
          "lower_error_bar": {"x": 96.6, "y": 86.4}
        }
      ]
    }
  ]
}
```

### Metrics CSV

**Summary Metrics:**

| Column | Description |
|--------|-------------|
| Metric | Name of the metric |
| Value | Numeric value |

**Per-Image Metrics:**

| Column | Description |
|--------|-------------|
| Image | Image filename |
| Points | Number of data points |
| Mean_Top_Error | Average top error (px) |
| Mean_Bottom_Error | Average bottom error (px) |
| Mean_Overall_Error | Average error (px) |
| Max_Top_Error | Maximum top error (px) |
| Max_Bottom_Error | Maximum bottom error (px) |

---

## Model Artifacts

### Published Models

| Model | Hub | Link |
|-------|-----|------|
| Chartqwen | HuggingFace | [Sayeem26s/Chartqwen](https://huggingface.co/Sayeem26s/Chartqwen) |

### Loading Chartqwen

```python
from transformers import AutoModelForVision2Seq, AutoProcessor
from peft import PeftModel
import torch

# Load base model
base_model = AutoModelForVision2Seq.from_pretrained(
    "Qwen/Qwen2.5-VL-7B-Instruct",
    torch_dtype=torch.float16,
    device_map="auto"
)

# Load LoRA adapter
model = PeftModel.from_pretrained(base_model, "Sayeem26s/Chartqwen")
model = model.merge_and_unload()  # Merge for faster inference

# Load processor
processor = AutoProcessor.from_pretrained("Qwen/Qwen2.5-VL-7B-Instruct")
```

---

## References

### Models

- [Qwen2.5-VL-7B-Instruct](https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct) - Base vision-language model
- [LoRA: Low-Rank Adaptation](https://arxiv.org/abs/2106.09685) - Parameter-efficient fine-tuning

### Libraries

- [OpenCV](https://opencv.org/) - Computer vision operations
- [Transformers](https://huggingface.co/docs/transformers) - Model loading and inference
- [PEFT](https://huggingface.co/docs/peft) - Parameter-efficient fine-tuning
- [scikit-learn](https://scikit-learn.org/) - Machine learning models

### Platform

- [Kaggle Notebooks](https://www.kaggle.com/docs/notebooks) - GPU compute environment

---

## License

This project is provided for educational and research purposes.

---

## Citation

If you use this work, please cite:

```bibtex
@misc{error-bar-detection-2024,
  title={Error Bar Detection in Scientific Charts using CV and VLM Approaches},
  author={Sayeem},
  year={2024},
  howpublished={\url{https://github.com/Sayeem-Velocity/Error-Bar-Detection-Project}}
}
```

---

<p align="center">
  <strong>Developed for automated scientific chart analysis</strong>
</p>
