{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0adcdb1",
   "metadata": {},
   "source": [
    "# Chartqwen Error Bar Detection - Inference\n",
    "\n",
    "This notebook performs inference using the fine-tuned Chartqwen model for error bar detection in scientific plots.\n",
    "\n",
    "## Task:\n",
    "- **Input**: Scientific plot image + data point coordinates (x, y)\n",
    "- **Output**: Error bar distances (topBarPixelDistance, bottomBarPixelDistance)\n",
    "\n",
    "## Model:\n",
    "- **Base**: Qwen2.5-VL-7B-Instruct\n",
    "- **Fine-tuned**: Sayeem26s/Chartqwen\n",
    "- **Method**: LoRA adapter loaded on top of base model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8183d2",
   "metadata": {},
   "source": [
    "## 0. Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0e0855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries for VLM inference\n",
    "!pip install transformers accelerate bitsandbytes -q\n",
    "!pip install peft -q\n",
    "!pip install pandas pillow tqdm -q\n",
    "!pip install qwen-vl-utils -q\n",
    "print(\"All libraries installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1879b669",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df931fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For image processing\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Transformers\n",
    "from transformers import (\n",
    "    Qwen2_5_VLForConditionalGeneration,\n",
    "    AutoProcessor,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "\n",
    "# PEFT for LoRA\n",
    "from peft import PeftModel\n",
    "\n",
    "# Check GPU\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU Memory: {gpu_mem:.1f} GB\")\n",
    "\n",
    "print(\"\\nLibraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2acc813",
   "metadata": {},
   "source": [
    "## 2. Configuration and Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24190f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths (Kaggle format)\n",
    "BASE_PATH = \"/kaggle/input/graph-plots\"\n",
    "TEST_IMAGES = os.path.join(BASE_PATH, \"Test\", \"images\")\n",
    "TEST_INPUT_LABELS = os.path.join(BASE_PATH, \"Test\", \"test_labels\")  # Input: x,y only\n",
    "TEST_GROUND_TRUTH = os.path.join(BASE_PATH, \"Test\", \"labels\")       # Ground truth: with error bars\n",
    "\n",
    "# Model configuration\n",
    "BASE_MODEL = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "FINETUNED_MODEL = \"Sayeem26s/Chartqwen\"  # Your fine-tuned model\n",
    "\n",
    "# Inference settings\n",
    "IMAGE_MAX_SIZE = 768\n",
    "MAX_NEW_TOKENS = 2048\n",
    "TEMPERATURE = 0.0  # Deterministic for consistent results\n",
    "\n",
    "print(f\"Base Model: {BASE_MODEL}\")\n",
    "print(f\"Fine-tuned Model: {FINETUNED_MODEL}\")\n",
    "print(f\"Test images: {TEST_IMAGES}\")\n",
    "print(f\"Test input labels: {TEST_INPUT_LABELS}\")\n",
    "print(f\"Ground truth: {TEST_GROUND_TRUTH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d19d620",
   "metadata": {},
   "source": [
    "## 3. Load Fine-tuned Model with LoRA Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce66e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chartqwen_model():\n",
    "    \"\"\"\n",
    "    Load Chartqwen fine-tuned model with LoRA adapter.\n",
    "    Uses FP16 precision for stable inference.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"LOADING CHARTQWEN MODEL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nLoading base model: {BASE_MODEL}\")\n",
    "    print(\"This may take 2-3 minutes...\")\n",
    "    \n",
    "    # Load processor\n",
    "    processor = AutoProcessor.from_pretrained(FINETUNED_MODEL, trust_remote_code=True)\n",
    "    print(\"Processor loaded!\")\n",
    "    \n",
    "    # Load base model with FP16\n",
    "    base_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "        BASE_MODEL,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Loading LoRA adapter from: {FINETUNED_MODEL}\")\n",
    "    \n",
    "    # Load fine-tuned LoRA adapter\n",
    "    model = PeftModel.from_pretrained(\n",
    "        base_model,\n",
    "        FINETUNED_MODEL,\n",
    "        torch_dtype=torch.float16,\n",
    "    )\n",
    "    \n",
    "    # Merge LoRA weights for faster inference\n",
    "    model = model.merge_and_unload()\n",
    "    \n",
    "    model.eval()\n",
    "    print(\"Model loaded with LoRA adapter!\")\n",
    "    \n",
    "    # Print memory usage\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9\n",
    "        print(f\"GPU Memory Used: {allocated:.2f} GB\")\n",
    "    \n",
    "    return model, processor\n",
    "\n",
    "\n",
    "# Load the model\n",
    "model, processor = load_chartqwen_model()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL READY FOR INFERENCE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9348422",
   "metadata": {},
   "source": [
    "## 4. Define System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a precise error bar detection system for scientific plots.\n",
    "Given an image of a scientific plot and data point coordinates, detect the error bars.\n",
    "For each point, output the pixel distance from the data point to the top and bottom of the error bar.\n",
    "If no error bar exists for a point, output 0 for both distances.\"\"\"\n",
    "\n",
    "print(\"System prompt defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a18e507",
   "metadata": {},
   "source": [
    "## 5. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38747dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_input(json_path):\n",
    "    \"\"\"Load test input JSON (contains only x,y coordinates)\"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_ground_truth(json_path):\n",
    "    \"\"\"Load ground truth JSON (contains error bar distances)\"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_image_as_pil(image_path):\n",
    "    \"\"\"Load image as PIL Image\"\"\"\n",
    "    return Image.open(image_path).convert('RGB')\n",
    "\n",
    "def create_input_prompt(input_points: List[Dict]) -> str:\n",
    "    \"\"\"\n",
    "    Create the input prompt with data point coordinates.\n",
    "    \"\"\"\n",
    "    points_str = json.dumps(input_points, indent=2)\n",
    "    \n",
    "    prompt = f\"\"\"Analyze this scientific plot image and detect error bars for the following data points:\n",
    "\n",
    "{points_str}\n",
    "\n",
    "For each point, measure:\n",
    "- topBarPixelDistance: pixel distance from data point to top of error bar (0 if none)\n",
    "- bottomBarPixelDistance: pixel distance from data point to bottom of error bar (0 if none)\n",
    "\n",
    "Output as JSON array:\n",
    "[\n",
    "  {{\"x\": <x>, \"y\": <y>, \"topBarPixelDistance\": <top>, \"bottomBarPixelDistance\": <bottom>}}\n",
    "]\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def parse_response(response_text: str, original_points: List[Dict]) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Parse model response to extract error bar measurements.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Clean response\n",
    "        cleaned = response_text.strip()\n",
    "        \n",
    "        # Remove markdown code blocks\n",
    "        if '```json' in cleaned:\n",
    "            start = cleaned.find('```json') + 7\n",
    "            end = cleaned.find('```', start)\n",
    "            if end > start:\n",
    "                cleaned = cleaned[start:end].strip()\n",
    "        elif '```' in cleaned:\n",
    "            start = cleaned.find('```') + 3\n",
    "            end = cleaned.find('```', start)\n",
    "            if end > start:\n",
    "                cleaned = cleaned[start:end].strip()\n",
    "        \n",
    "        # Find JSON\n",
    "        if cleaned.startswith('['):\n",
    "            json_str = cleaned\n",
    "        else:\n",
    "            start_idx = cleaned.find('[')\n",
    "            end_idx = cleaned.rfind(']') + 1\n",
    "            if start_idx >= 0 and end_idx > start_idx:\n",
    "                json_str = cleaned[start_idx:end_idx]\n",
    "            else:\n",
    "                return None\n",
    "        \n",
    "        # Parse JSON\n",
    "        parsed = json.loads(json_str)\n",
    "        \n",
    "        # Convert to standard format\n",
    "        measurements = []\n",
    "        for item in parsed:\n",
    "            x = float(item.get('x', 0))\n",
    "            y = float(item.get('y', 0))\n",
    "            top_dist = float(item.get('topBarPixelDistance', 0))\n",
    "            bottom_dist = float(item.get('bottomBarPixelDistance', 0))\n",
    "            \n",
    "            measurements.append({\n",
    "                \"data_point\": {\"x\": x, \"y\": y},\n",
    "                \"upper_error_bar\": {\"x\": x, \"y\": y - top_dist},\n",
    "                \"lower_error_bar\": {\"x\": x, \"y\": y + bottom_dist},\n",
    "                \"topBarPixelDistance\": top_dist,\n",
    "                \"bottomBarPixelDistance\": bottom_dist\n",
    "            })\n",
    "        \n",
    "        return {\"measurements\": measurements}\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parse error: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Parse error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c27f48",
   "metadata": {},
   "source": [
    "## 6. Model Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d12a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_error_bars(image_path: str, data_points: List[Dict]) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Infer error bars for given data points in an image.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the plot image\n",
    "        data_points: List of {\"x\": float, \"y\": float}\n",
    "    \n",
    "    Returns:\n",
    "        Dict with measurements or None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and resize image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if max(image.size) > IMAGE_MAX_SIZE:\n",
    "            ratio = IMAGE_MAX_SIZE / max(image.size)\n",
    "            new_size = (int(image.size[0] * ratio), int(image.size[1] * ratio))\n",
    "            image = image.resize(new_size, Image.BILINEAR)\n",
    "        \n",
    "        # Create prompt\n",
    "        input_prompt = create_input_prompt(data_points)\n",
    "        \n",
    "        # Create messages\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \"image\": image},\n",
    "                    {\"type\": \"text\", \"text\": f\"{SYSTEM_PROMPT}\\n\\n{input_prompt}\"}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Apply chat template\n",
    "        text = processor.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        \n",
    "        # Process inputs\n",
    "        inputs = processor(\n",
    "            text=[text],\n",
    "            images=[image],\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "        \n",
    "        # Generate\n",
    "        num_points = len(data_points)\n",
    "        max_tokens = min(MAX_NEW_TOKENS, max(512, num_points * 80))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_tokens,\n",
    "                do_sample=False,\n",
    "                temperature=TEMPERATURE,\n",
    "                num_beams=1,\n",
    "                pad_token_id=processor.tokenizer.pad_token_id,\n",
    "            )\n",
    "        \n",
    "        # Decode\n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids):]\n",
    "            for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        response = processor.batch_decode(\n",
    "            generated_ids_trimmed,\n",
    "            skip_special_tokens=True\n",
    "        )[0]\n",
    "        \n",
    "        # Parse response\n",
    "        result = parse_response(response, data_points)\n",
    "        \n",
    "        # Cleanup\n",
    "        del inputs, generated_ids, image\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Inference error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Inference function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224c9442",
   "metadata": {},
   "source": [
    "## 7. Convert to Output Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b0de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_vlm_to_standard_format(result: Dict, line_name: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Convert VLM measurements to standard prediction format with pixel distances.\n",
    "    \"\"\"\n",
    "    points = []\n",
    "    \n",
    "    measurements = result.get('measurements', [])\n",
    "    \n",
    "    for measure in measurements:\n",
    "        data_pt = measure['data_point']\n",
    "        upper_bar = measure['upper_error_bar']\n",
    "        lower_bar = measure['lower_error_bar']\n",
    "        \n",
    "        x = data_pt['x']\n",
    "        y = data_pt['y']\n",
    "        \n",
    "        # Calculate pixel distances\n",
    "        top_dist = abs(y - upper_bar['y'])  # Distance to upper error bar\n",
    "        bottom_dist = abs(lower_bar['y'] - y)  # Distance to lower error bar\n",
    "        dev_dist = max(top_dist, bottom_dist)\n",
    "        \n",
    "        points.append({\n",
    "            \"x\": x,\n",
    "            \"y\": y,\n",
    "            \"label\": \"\",\n",
    "            \"topBarPixelDistance\": float(top_dist),\n",
    "            \"bottomBarPixelDistance\": float(bottom_dist),\n",
    "            \"deviationPixelDistance\": float(dev_dist)\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        \"label\": {\"lineName\": line_name},\n",
    "        \"points\": points\n",
    "    }\n",
    "\n",
    "def convert_to_output_format(image_file: str, predictions: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    Convert to final output format with error bar endpoints.\n",
    "    \"\"\"\n",
    "    error_bars = []\n",
    "    \n",
    "    for pred_line in predictions:\n",
    "        line_name = pred_line.get('label', {}).get('lineName', '')\n",
    "        pred_points = [p for p in pred_line.get('points', []) \n",
    "                      if p.get('label', '') not in ['xmin', 'xmax', 'ymin', 'ymax']]\n",
    "        \n",
    "        points_data = []\n",
    "        for point in pred_points:\n",
    "            x = point['x']\n",
    "            y = point['y']\n",
    "            top_dist = point['topBarPixelDistance']\n",
    "            bottom_dist = point['bottomBarPixelDistance']\n",
    "            \n",
    "            point_data = {\n",
    "                \"data_point\": {\"x\": x, \"y\": y},\n",
    "                \"upper_error_bar\": {\"x\": x, \"y\": y - top_dist},\n",
    "                \"lower_error_bar\": {\"x\": x, \"y\": y + bottom_dist}\n",
    "            }\n",
    "            \n",
    "            points_data.append(point_data)\n",
    "        \n",
    "        line_data = {\n",
    "            \"lineName\": line_name,\n",
    "            \"points\": points_data\n",
    "        }\n",
    "        \n",
    "        error_bars.append(line_data)\n",
    "    \n",
    "    return {\n",
    "        \"image_file\": image_file,\n",
    "        \"model\": \"Chartqwen\",\n",
    "        \"error_bars\": error_bars\n",
    "    }\n",
    "\n",
    "print(\"Format conversion functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df0abbc",
   "metadata": {},
   "source": [
    "## 8. Test on Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441debd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_label_files = sorted([f for f in os.listdir(TEST_INPUT_LABELS) if f.endswith('.json')])[:1]\n",
    "\n",
    "if test_label_files:\n",
    "    test_file = test_label_files[0]\n",
    "    print(f\"Testing on: {test_file}\\n\")\n",
    "    \n",
    "    # Load input labels (x, y only)\n",
    "    test_input = load_test_input(os.path.join(TEST_INPUT_LABELS, test_file))\n",
    "    \n",
    "    image_file = test_input['image_file']\n",
    "    image_path = os.path.join(TEST_IMAGES, image_file)\n",
    "    \n",
    "    # Get data points\n",
    "    data_points = []\n",
    "    for line_data in test_input.get('data_points', []):\n",
    "        for pt in line_data.get('points', []):\n",
    "            data_points.append({\"x\": round(pt['x'], 1), \"y\": round(pt['y'], 1)})\n",
    "    \n",
    "    print(f\"Image: {image_path}\")\n",
    "    print(f\"Data points: {len(data_points)}\")\n",
    "    if data_points:\n",
    "        print(f\"First point: {data_points[0]}\")\n",
    "    \n",
    "    # Run inference\n",
    "    print(\"\\nRunning inference...\")\n",
    "    result = infer_error_bars(image_path, data_points)\n",
    "    \n",
    "    if result and 'measurements' in result:\n",
    "        print(f\"\\nInference successful!\")\n",
    "        print(f\"Got {len(result['measurements'])} measurements\")\n",
    "        \n",
    "        print(\"\\nFirst 3 measurements:\")\n",
    "        for i, m in enumerate(result['measurements'][:3]):\n",
    "            print(f\"  [{i+1}] Point: ({m['data_point']['x']:.1f}, {m['data_point']['y']:.1f})\")\n",
    "            print(f\"       Top: {m['topBarPixelDistance']:.1f}px, Bottom: {m['bottomBarPixelDistance']:.1f}px\")\n",
    "    else:\n",
    "        print(\"Inference failed\")\n",
    "else:\n",
    "    print(\"No test files found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5558b0cb",
   "metadata": {},
   "source": [
    "## 9. Process All Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f62a309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all test files\n",
    "all_test_files = sorted([f for f in os.listdir(TEST_INPUT_LABELS) if f.endswith('.json')])\n",
    "print(f\"Processing {len(all_test_files)} test files...\\n\")\n",
    "\n",
    "all_predictions = {}\n",
    "all_results = []\n",
    "failed_count = 0\n",
    "processed_count = 0\n",
    "\n",
    "for i, test_file in enumerate(tqdm(all_test_files, desc=\"Processing test files\")):\n",
    "    try:\n",
    "        # Load input\n",
    "        test_input = load_test_input(os.path.join(TEST_INPUT_LABELS, test_file))\n",
    "        \n",
    "        image_file = test_input['image_file']\n",
    "        image_path = os.path.join(TEST_IMAGES, image_file)\n",
    "        \n",
    "        # Get all data points\n",
    "        all_points = []\n",
    "        for line_data in test_input.get('data_points', []):\n",
    "            for pt in line_data.get('points', []):\n",
    "                all_points.append({\"x\": round(pt['x'], 1), \"y\": round(pt['y'], 1)})\n",
    "        \n",
    "        # Run inference\n",
    "        result = infer_error_bars(image_path, all_points)\n",
    "        \n",
    "        if result and 'measurements' in result:\n",
    "            all_predictions[test_file] = {\n",
    "                'image_file': image_file,\n",
    "                'measurements': result['measurements']\n",
    "            }\n",
    "            processed_count += 1\n",
    "        else:\n",
    "            failed_count += 1\n",
    "        \n",
    "        # Progress\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"âœ“ Processed {i+1}/{len(all_test_files)} | Success: {processed_count} | Failed: {failed_count}\")\n",
    "        \n",
    "        # Clear cache periodically\n",
    "        if (i + 1) % 5 == 0 and torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    except Exception as e:\n",
    "        failed_count += 1\n",
    "        if failed_count <= 5:\n",
    "            print(f\"Error on {test_file}: {e}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PROCESSING COMPLETE\")\n",
    "print(f\"Processed: {processed_count}\")\n",
    "print(f\"Failed: {failed_count}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dcaeb3",
   "metadata": {},
   "source": [
    "## 10. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6932b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions: Dict, ground_truth_dir: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculate evaluation metrics.\n",
    "    \"\"\"\n",
    "    all_top_errors = []\n",
    "    all_bottom_errors = []\n",
    "    \n",
    "    for json_file, pred_data in predictions.items():\n",
    "        try:\n",
    "            # Load ground truth\n",
    "            gt_path = os.path.join(ground_truth_dir, json_file)\n",
    "            if not os.path.exists(gt_path):\n",
    "                continue\n",
    "            \n",
    "            with open(gt_path, 'r') as f:\n",
    "                gt_data = json.load(f)\n",
    "            \n",
    "            # Collect all GT points\n",
    "            gt_points = []\n",
    "            for line_data in gt_data:\n",
    "                for pt in line_data.get('points', []):\n",
    "                    if pt.get('label', '') not in ['xmin', 'xmax', 'ymin', 'ymax']:\n",
    "                        gt_points.append(pt)\n",
    "            \n",
    "            # Compare with predictions\n",
    "            pred_measurements = pred_data['measurements']\n",
    "            \n",
    "            for pred_m, gt_pt in zip(pred_measurements, gt_points):\n",
    "                pred_top = pred_m.get('topBarPixelDistance', 0)\n",
    "                pred_bottom = pred_m.get('bottomBarPixelDistance', 0)\n",
    "                gt_top = gt_pt.get('topBarPixelDistance', 0)\n",
    "                gt_bottom = gt_pt.get('bottomBarPixelDistance', 0)\n",
    "                \n",
    "                all_top_errors.append(abs(pred_top - gt_top))\n",
    "                all_bottom_errors.append(abs(pred_bottom - gt_bottom))\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    if not all_top_errors:\n",
    "        return None\n",
    "    \n",
    "    all_mean_errors = [(t + b) / 2 for t, b in zip(all_top_errors, all_bottom_errors)]\n",
    "    \n",
    "    metrics = {\n",
    "        'num_points': len(all_top_errors),\n",
    "        'mean_top_error': np.mean(all_top_errors),\n",
    "        'mean_bottom_error': np.mean(all_bottom_errors),\n",
    "        'mean_overall_error': np.mean(all_mean_errors),\n",
    "        'median_top_error': np.median(all_top_errors),\n",
    "        'median_bottom_error': np.median(all_bottom_errors),\n",
    "        'std_top_error': np.std(all_top_errors),\n",
    "        'std_bottom_error': np.std(all_bottom_errors),\n",
    "        'accuracy_5px': sum(1 for e in all_mean_errors if e <= 5) / len(all_mean_errors) * 100,\n",
    "        'accuracy_10px': sum(1 for e in all_mean_errors if e <= 10) / len(all_mean_errors) * 100,\n",
    "        'accuracy_20px': sum(1 for e in all_mean_errors if e <= 20) / len(all_mean_errors) * 100,\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate metrics\n",
    "if all_predictions:\n",
    "    print(\"Calculating evaluation metrics...\")\n",
    "    metrics = calculate_metrics(all_predictions, TEST_GROUND_TRUTH)\n",
    "    \n",
    "    if metrics:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"EVALUATION RESULTS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"\\nTotal Points Evaluated: {metrics['num_points']}\")\n",
    "        print(f\"\\nPixel Error:\")\n",
    "        print(f\"  Mean Top Error: {metrics['mean_top_error']:.2f} px\")\n",
    "        print(f\"  Mean Bottom Error: {metrics['mean_bottom_error']:.2f} px\")\n",
    "        print(f\"  Mean Overall Error: {metrics['mean_overall_error']:.2f} px\")\n",
    "        print(f\"  Median Top Error: {metrics['median_top_error']:.2f} px\")\n",
    "        print(f\"  Median Bottom Error: {metrics['median_bottom_error']:.2f} px\")\n",
    "        print(f\"  Std Top Error: {metrics['std_top_error']:.2f} px\")\n",
    "        print(f\"  Std Bottom Error: {metrics['std_bottom_error']:.2f} px\")\n",
    "        print(f\"\\nAccuracy:\")\n",
    "        print(f\"  Within 5px: {metrics['accuracy_5px']:.1f}%\")\n",
    "        print(f\"  Within 10px: {metrics['accuracy_10px']:.1f}%\")\n",
    "        print(f\"  Within 20px: {metrics['accuracy_20px']:.1f}%\")\n",
    "        print(\"=\"*60)\n",
    "    else:\n",
    "        print(\"No metrics calculated - check predictions and ground truth\")\n",
    "else:\n",
    "    print(\"No predictions to evaluate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca04257",
   "metadata": {},
   "source": [
    "## 11. Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc1df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "OUTPUT_PREDICTIONS_DIR = \"/kaggle/working/chartqwen_predictions\"\n",
    "os.makedirs(OUTPUT_PREDICTIONS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Saving {len(all_predictions)} prediction files...\\n\")\n",
    "\n",
    "for json_file, pred_data in all_predictions.items():\n",
    "    try:\n",
    "        # Convert to output format\n",
    "        output = {\n",
    "            \"image_file\": pred_data['image_file'],\n",
    "            \"model\": \"Chartqwen\",\n",
    "            \"error_bars\": [{\n",
    "                \"lineName\": \"\",\n",
    "                \"points\": [\n",
    "                    {\n",
    "                        \"data_point\": m['data_point'],\n",
    "                        \"upper_error_bar\": m['upper_error_bar'],\n",
    "                        \"lower_error_bar\": m['lower_error_bar']\n",
    "                    }\n",
    "                    for m in pred_data['measurements']\n",
    "                ]\n",
    "            }]\n",
    "        }\n",
    "        \n",
    "        output_path = os.path.join(OUTPUT_PREDICTIONS_DIR, json_file)\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(output, f, indent=2)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {json_file}: {e}\")\n",
    "\n",
    "print(f\"Predictions saved to: {OUTPUT_PREDICTIONS_DIR}\")\n",
    "\n",
    "# Create ZIP\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "zip_path = f\"/kaggle/working/chartqwen_predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for f in os.listdir(OUTPUT_PREDICTIONS_DIR):\n",
    "        if f.endswith('.json'):\n",
    "            zipf.write(os.path.join(OUTPUT_PREDICTIONS_DIR, f), f\"predictions/{f}\")\n",
    "\n",
    "print(f\"ZIP created: {zip_path}\")\n",
    "print(f\"\\nDownload the ZIP file to get all predictions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59116d06",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates inference using the fine-tuned **Chartqwen** model for error bar detection.\n",
    "\n",
    "### Model Details:\n",
    "- **Base Model**: Qwen2.5-VL-7B-Instruct\n",
    "- **Fine-tuned**: Sayeem26s/Chartqwen\n",
    "- **Method**: LoRA adapter with FP16 precision\n",
    "- **Task**: Error bar detection in scientific plots\n",
    "\n",
    "### Input Format:\n",
    "- Image of scientific plot\n",
    "- Data point coordinates (x, y)\n",
    "\n",
    "### Output Format:\n",
    "- Error bar pixel distances (topBarPixelDistance, bottomBarPixelDistance)\n",
    "- Upper and lower error bar endpoints\n",
    "\n",
    "### Evaluation:\n",
    "- Mean pixel error\n",
    "- Accuracy within 5px, 10px, 20px thresholds\n",
    "\n",
    "### Model Hub:\n",
    "- HuggingFace: `Sayeem26s/Chartqwen`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
