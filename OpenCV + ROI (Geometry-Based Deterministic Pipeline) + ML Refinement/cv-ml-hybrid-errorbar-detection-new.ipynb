{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14642164,"sourceType":"datasetVersion","datasetId":9353118}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"a05bd145","cell_type":"markdown","source":"# CV + ML Hybrid Pipeline for Error Bar Detection\n\n## Objective\nCombine Computer Vision (CV) for coarse detection with Machine Learning (ML) regression for precision refinement.\n\n## Why Hybrid?\n\n### âŒ Pure CV Limitations:\n- **Brittle**: Fixed thresholds fail on varied plot styles\n- **Noise sensitive**: Edge detection struggles with low contrast\n- **No learning**: Can't adapt to dataset patterns\n\n### âŒ Pure ML Limitations:\n- **Data hungry**: Requires massive labeled datasets\n- **Black box**: No geometric understanding\n- **Overfits**: Learns dataset artifacts instead of error bars\n\n### âœ… Hybrid Advantages:\n- **CV provides structure**: Coarse geometric priors reduce search space\n- **ML refines precision**: Learns to correct CV mistakes from data\n- **Data efficient**: ML only needs to learn refinements, not full detection\n- **Robust**: CV catches obvious cases, ML fixes edge cases\n- **Explainable**: CV stage interpretable, ML stage measurable\n\n## Pipeline Architecture\n\n```\nInput Image â†’ CV Stem Detection â†’ Coarse Estimate â†’ ML Regression â†’ Refined Prediction\n              (Canny + Projection)  (top_dist, bot_dist)  (delta corrections)  (final pixels)\n```","metadata":{}},{"id":"9d7ee3b6","cell_type":"markdown","source":"## 1. Setup and Imports","metadata":{}},{"id":"e6d4a090","cell_type":"code","source":"# Install required packages\n!pip install opencv-python scikit-learn pandas numpy matplotlib pillow tqdm -q\nprint(\"Libraries installed successfully!\")","metadata":{"execution":{"iopub.status.busy":"2026-01-28T17:02:00.748146Z","iopub.execute_input":"2026-01-28T17:02:00.748413Z","iopub.status.idle":"2026-01-28T17:02:05.131787Z","shell.execute_reply.started":"2026-01-28T17:02:00.748390Z","shell.execute_reply":"2026-01-28T17:02:05.131105Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Libraries installed successfully!\n","output_type":"stream"}],"execution_count":1},{"id":"ce69dbf9","cell_type":"code","source":"import cv2\nimport numpy as np\nimport pandas as pd\nimport json\nimport os\nfrom pathlib import Path\nfrom typing import List, Dict, Tuple, Optional\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ML imports\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\nprint(\"All libraries imported successfully!\")","metadata":{"execution":{"iopub.status.busy":"2026-01-28T17:02:05.133242Z","iopub.execute_input":"2026-01-28T17:02:05.133485Z","iopub.status.idle":"2026-01-28T17:02:06.793108Z","shell.execute_reply.started":"2026-01-28T17:02:05.133457Z","shell.execute_reply":"2026-01-28T17:02:06.792385Z"},"trusted":true},"outputs":[{"name":"stdout","text":"All libraries imported successfully!\n","output_type":"stream"}],"execution_count":2},{"id":"789166b9","cell_type":"markdown","source":"## 2. Configuration and Paths","metadata":{}},{"id":"354891d8","cell_type":"code","source":"# Data paths - Kaggle format\nBASE_PATH = \"/kaggle/input/graph-plots\"\nTRAIN_IMAGES = os.path.join(BASE_PATH, \"Train\", \"images\")\nTRAIN_LABELS = os.path.join(BASE_PATH, \"Train\", \"labels\")\nTEST_IMAGES = os.path.join(BASE_PATH, \"Test\", \"images\")\nTEST_INPUT_LABELS = os.path.join(BASE_PATH, \"Test\", \"test_labels\")\nTEST_GROUND_TRUTH = os.path.join(BASE_PATH, \"Test\", \"labels\")\n\n# For local testing, use:\n# BASE_PATH = \"dataset task\"\n# TRAIN_IMAGES = os.path.join(BASE_PATH, \"images\")\n# TRAIN_LABELS = os.path.join(BASE_PATH, \"labels\")\n\n# CV Parameters (will be tuned)\nCV_CONFIG = {\n    'roi_size': 50,           # ROI extraction radius\n    'canny_low': 50,          # Canny lower threshold\n    'canny_high': 150,        # Canny upper threshold\n    'min_line_length': 20,    # Minimum error bar length\n    'max_gap': 5,             # Max gap in line detection\n    'vertical_tolerance': 3   # Max x deviation for vertical line\n}\n\n# Output directory\nOUTPUT_DIR = \"/kaggle/working\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nprint(f\"Train images: {TRAIN_IMAGES}\")\nprint(f\"Train labels: {TRAIN_LABELS}\")\nprint(f\"Test images: {TEST_IMAGES}\")\nprint(f\"Test input labels: {TEST_INPUT_LABELS}\")\nprint(f\"Test ground truth: {TEST_GROUND_TRUTH}\")\nprint(f\"Output directory: {OUTPUT_DIR}\")","metadata":{"execution":{"iopub.status.busy":"2026-01-28T17:02:06.793960Z","iopub.execute_input":"2026-01-28T17:02:06.794345Z","iopub.status.idle":"2026-01-28T17:02:06.800384Z","shell.execute_reply.started":"2026-01-28T17:02:06.794323Z","shell.execute_reply":"2026-01-28T17:02:06.799785Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Train images: /kaggle/input/graph-plots/Train/images\nTrain labels: /kaggle/input/graph-plots/Train/labels\nTest images: /kaggle/input/graph-plots/Test/images\nTest input labels: /kaggle/input/graph-plots/Test/test_labels\nTest ground truth: /kaggle/input/graph-plots/Test/labels\nOutput directory: /kaggle/working\n","output_type":"stream"}],"execution_count":3},{"id":"d88af10b","cell_type":"markdown","source":"## 3. Data Loading Functions","metadata":{}},{"id":"a27e8eea","cell_type":"code","source":"def load_json_label(json_path: str) -> Dict:\n    \"\"\"Load label JSON file\"\"\"\n    with open(json_path, 'r') as f:\n        return json.load(f)\n\ndef load_training_data():\n    \"\"\"Load all training images and labels\"\"\"\n    label_files = sorted([f for f in os.listdir(TRAIN_LABELS) if f.endswith('.json')])\n    \n    training_data = []\n    \n    print(f\"Loading {len(label_files)} training samples...\")\n    \n    for label_file in tqdm(label_files):\n        label_data = load_json_label(os.path.join(TRAIN_LABELS, label_file))\n        \n        # Extract image filename from label\n        if 'image_file' in label_data:\n            image_file = label_data['image_file']\n        else:\n            # Assume same name with .png extension\n            image_file = label_file.replace('.json', '.png')\n        \n        image_path = os.path.join(TRAIN_IMAGES, image_file)\n        \n        if not os.path.exists(image_path):\n            continue\n        \n        # Parse data points\n        for line_data in label_data:\n            if 'points' not in line_data:\n                continue\n            \n            line_name = line_data.get('label', {}).get('lineName', '')\n            \n            for point in line_data['points']:\n                # Skip axis labels\n                if point.get('label', '') in ['xmin', 'xmax', 'ymin', 'ymax']:\n                    continue\n                \n                training_data.append({\n                    'image_path': image_path,\n                    'label_file': label_file,\n                    'line_name': line_name,\n                    'x': point['x'],\n                    'y': point['y'],\n                    'topBarPixelDistance': point.get('topBarPixelDistance', 0),\n                    'bottomBarPixelDistance': point.get('bottomBarPixelDistance', 0)\n                })\n    \n    df = pd.DataFrame(training_data)\n    print(f\"Loaded {len(df)} data points from {len(df['image_path'].unique())} images\")\n    \n    return df\n\nprint(\"Data loading functions defined!\")","metadata":{"execution":{"iopub.status.busy":"2026-01-28T17:02:06.802190Z","iopub.execute_input":"2026-01-28T17:02:06.802423Z","iopub.status.idle":"2026-01-28T17:02:06.818625Z","shell.execute_reply.started":"2026-01-28T17:02:06.802403Z","shell.execute_reply":"2026-01-28T17:02:06.818126Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Data loading functions defined!\n","output_type":"stream"}],"execution_count":4},{"id":"1ad3f1b4","cell_type":"markdown","source":"## 4. CV Stem Detection Module\n\n### Coarse Detection Strategy:\n1. Extract ROI around data point\n2. Apply edge detection (Canny)\n3. Detect vertical lines (HoughLinesP)\n4. Find line closest to point center\n5. Extract coarse top/bottom distances","metadata":{}},{"id":"2ce94cfa","cell_type":"code","source":"def extract_roi(image: np.ndarray, x: int, y: int, roi_size: int = 50) -> Tuple[np.ndarray, int, int]:\n    \"\"\"Extract ROI around data point\"\"\"\n    h, w = image.shape[:2]\n    \n    x1 = max(0, x - roi_size)\n    x2 = min(w, x + roi_size)\n    y1 = max(0, y - roi_size)\n    y2 = min(h, y + roi_size)\n    \n    roi = image[y1:y2, x1:x2]\n    \n    # Local coordinates of center point\n    local_x = x - x1\n    local_y = y - y1\n    \n    return roi, local_x, local_y\n\ndef detect_error_bar_cv(image_path: str, x: int, y: int, config: Dict) -> Dict:\n    \"\"\"\n    CV-based coarse error bar detection.\n    \n    Returns:\n        coarse_top_dist: estimated distance to top of error bar\n        coarse_bottom_dist: estimated distance to bottom of error bar\n        confidence: detection confidence [0-1]\n    \"\"\"\n    # Load image\n    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n    if img is None:\n        return {'coarse_top_dist': 0, 'coarse_bottom_dist': 0, 'confidence': 0}\n    \n    # Extract ROI\n    roi, local_x, local_y = extract_roi(img, int(x), int(y), config['roi_size'])\n    \n    if roi.size == 0:\n        return {'coarse_top_dist': 0, 'coarse_bottom_dist': 0, 'confidence': 0}\n    \n    # Edge detection\n    edges = cv2.Canny(roi, config['canny_low'], config['canny_high'])\n    \n    # Detect vertical lines\n    lines = cv2.HoughLinesP(\n        edges,\n        rho=1,\n        theta=np.pi / 180,\n        threshold=20,\n        minLineLength=config['min_line_length'],\n        maxLineGap=config['max_gap']\n    )\n    \n    if lines is None:\n        return {'coarse_top_dist': 0, 'coarse_bottom_dist': 0, 'confidence': 0}\n    \n    # Find vertical lines near the data point\n    best_line = None\n    min_dist = float('inf')\n    \n    for line in lines:\n        x1, y1, x2, y2 = line[0]\n        \n        # Check if line is vertical\n        if abs(x1 - x2) > config['vertical_tolerance']:\n            continue\n        \n        # Check proximity to data point\n        line_x = (x1 + x2) / 2\n        dist = abs(line_x - local_x)\n        \n        if dist < min_dist:\n            min_dist = dist\n            best_line = (x1, y1, x2, y2)\n    \n    if best_line is None or min_dist > 10:\n        return {'coarse_top_dist': 0, 'coarse_bottom_dist': 0, 'confidence': 0}\n    \n    # Calculate distances\n    x1, y1, x2, y2 = best_line\n    top_y = min(y1, y2)\n    bottom_y = max(y1, y2)\n    \n    coarse_top_dist = abs(local_y - top_y)\n    coarse_bottom_dist = abs(bottom_y - local_y)\n    \n    # Confidence based on proximity\n    confidence = max(0, 1 - min_dist / 10)\n    \n    return {\n        'coarse_top_dist': float(coarse_top_dist),\n        'coarse_bottom_dist': float(coarse_bottom_dist),\n        'confidence': float(confidence)\n    }\n\nprint(\"CV stem detection module defined!\")","metadata":{"execution":{"iopub.status.busy":"2026-01-28T17:02:06.819491Z","iopub.execute_input":"2026-01-28T17:02:06.819755Z","iopub.status.idle":"2026-01-28T17:02:06.834533Z","shell.execute_reply.started":"2026-01-28T17:02:06.819729Z","shell.execute_reply":"2026-01-28T17:02:06.834036Z"},"trusted":true},"outputs":[{"name":"stdout","text":"CV stem detection module defined!\n","output_type":"stream"}],"execution_count":5},{"id":"d98a3897","cell_type":"markdown","source":"## 5. Feature Extraction for ML\n\n### Features:\n- ROI image features (HOG, intensity statistics)\n- Coarse CV estimates (top_dist, bottom_dist)\n- Confidence score\n- Local context features","metadata":{}},{"id":"a75aa9bb","cell_type":"markdown","source":"### ðŸ“Š Feature Engineering Details: 14 Refined Features\n\nThe hybrid pipeline uses **14 carefully selected features** to predict error bar distances:\n\n#### **ROI Image Features (11 features)**\n\nThese features capture essential visual characteristics of the region around each data point:\n\n**1-4. Basic Intensity Statistics**\n- `mean_intensity`: Average pixel brightness in ROI\n- `std_intensity`: Brightness variation (uniformity)\n- `min_intensity`: Darkest pixel value\n- `max_intensity`: Brightest pixel value\n\n**5-6. Vertical Gradient Features**\n- `grad_y_mean`: Average vertical edge strength (detects vertical lines)\n- `grad_y_std`: Variation in vertical gradients\n\n**7. Edge Density**\n- `edge_density`: Percentage of edge pixels (Canny) in ROI\n- Higher for error bars with clear boundaries\n\n**8-11. Center Column Profile**\n- `center_col_mean`: Average brightness of center vertical stripe\n- `center_col_std`: Variation along center (detects stems)\n- `center_col_min`: Darkest point in center\n- `center_col_max`: Brightest point in center\n\n#### **CV Coarse Detection Features (3 features)**\n\nThese are geometric estimates from computer vision:\n\n**12. Coarse Top Distance**\n- `cv_top_dist`: Estimated distance from data point to top of detected vertical line (pixels)\n- From HoughLinesP line detection\n\n**13. Coarse Bottom Distance**\n- `cv_bottom_dist`: Estimated distance from data point to bottom of detected vertical line (pixels)\n- From HoughLinesP line detection\n\n**14. Confidence Score**\n- `cv_confidence`: How confident CV is in detection (0-1)\n- Based on proximity of detected line to data point\n- Higher when vertical line is exactly at data point x-coordinate\n\n### ðŸ”„ How Features Are Created\n\n```python\n# Step 1: Extract ROI (100x100 window around point)\nroi = image[y-50:y+50, x-50:x+50]\n\n# Step 2: Calculate ROI features (11)\n- Intensity stats from roi pixels\n- Sobel gradients for vertical edges\n- Canny edge detection for density\n- Statistical analysis of center column\n\n# Step 3: Run CV detection (3)\n- Apply Canny edge detection\n- HoughLinesP to find vertical lines\n- Match nearest line to data point\n- Extract top/bottom endpoints\n\n# Step 4: Concatenate into feature vector\nfeatures = [roi_feat_1, ..., roi_feat_11, cv_top, cv_bottom, cv_conf]\n# Total: 14 features\n```\n\n### ðŸŽ¯ Why This Works\n\n- **Refined feature set**: Removed redundant variance and padding features\n- **ROI features** capture essential visual patterns (what error bars look like)\n- **CV features** provide geometric structure (where error bars are)\n- **ML model** learns to combine both for accurate predictions\n- **Simpler = Better generalization**: 14 focused features vs 23 with redundancy","metadata":{}},{"id":"6f54028b","cell_type":"code","source":"def extract_roi_features(image_path: str, x: int, y: int, roi_size: int = 50) -> np.ndarray:\n    \"\"\"\n    Extract features from ROI for ML model.\n\n    Features (11 total):\n    - Basic intensity statistics (4)\n    - Vertical gradient (2)\n    - Edge density (1)\n    - Center column profile (4)\n    \"\"\"\n    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n    if img is None:\n        return np.zeros(11)\n\n    roi, local_x, local_y = extract_roi(img, int(x), int(y), roi_size)\n\n    if roi.size == 0:\n        return np.zeros(11)\n\n    features = []\n\n    # Basic intensity statistics\n    features.append(np.mean(roi))\n    features.append(np.std(roi))\n    features.append(np.min(roi))\n    features.append(np.max(roi))\n\n    # Vertical gradient\n    grad_y = cv2.Sobel(roi, cv2.CV_64F, 0, 1, ksize=3)\n    features.append(np.mean(np.abs(grad_y)))\n    features.append(np.std(grad_y))\n\n    # Edge density\n    edges = cv2.Canny(roi, 50, 150)\n    features.append(np.sum(edges > 0) / edges.size)\n\n    # Center column profile\n    if roi.shape[1] > 0:\n        center_col = roi[:, roi.shape[1] // 2]\n        features.append(np.mean(center_col))\n        features.append(np.std(center_col))\n        features.append(np.min(center_col))\n        features.append(np.max(center_col))\n    else:\n        features.extend([0, 0, 0, 0])\n\n    return np.array(features)\n\n\ndef create_ml_features(row: pd.Series, config: Dict) -> Tuple[np.ndarray, Dict]:\n    \"\"\"\n    Create full feature vector for ML model.\n\n    Features = [ROI features (11) + CV estimates (3)] = 14 features\n    \"\"\"\n    # CV coarse estimates\n    cv_result = detect_error_bar_cv(\n        row['image_path'],\n        row['x'],\n        row['y'],\n        config\n    )\n\n    # ROI features\n    roi_features = extract_roi_features(\n        row['image_path'],\n        row['x'],\n        row['y'],\n        config['roi_size']\n    )\n\n    # Combine features\n    features = np.concatenate([\n        roi_features,\n        [\n            cv_result['coarse_top_dist'],\n            cv_result['coarse_bottom_dist'],\n            cv_result['confidence']\n        ]\n    ])\n\n    return features, cv_result\n\n\nprint(\"Feature extraction functions defined!\")","metadata":{"execution":{"iopub.status.busy":"2026-01-28T17:02:06.835335Z","iopub.execute_input":"2026-01-28T17:02:06.835676Z","iopub.status.idle":"2026-01-28T17:02:06.849069Z","shell.execute_reply.started":"2026-01-28T17:02:06.835653Z","shell.execute_reply":"2026-01-28T17:02:06.848402Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Feature extraction functions defined!\n","output_type":"stream"}],"execution_count":6},{"id":"d832a016","cell_type":"markdown","source":"## 6. Load Training Data and Extract Features","metadata":{}},{"id":"5eef28dd","cell_type":"code","source":"# Load training data\ntrain_df = load_training_data()\n\nprint(f\"\\nDataset statistics:\")\nprint(f\"Total points: {len(train_df)}\")\nprint(f\"Unique images: {train_df['image_path'].nunique()}\")\nprint(f\"\\nError bar statistics:\")\nprint(f\"Mean top distance: {train_df['topBarPixelDistance'].mean():.2f}px\")\nprint(f\"Mean bottom distance: {train_df['bottomBarPixelDistance'].mean():.2f}px\")\nprint(f\"Points with error bars: {(train_df['topBarPixelDistance'] > 0).sum()} ({(train_df['topBarPixelDistance'] > 0).mean()*100:.1f}%)\")","metadata":{"execution":{"iopub.status.busy":"2026-01-28T17:02:06.849878Z","iopub.execute_input":"2026-01-28T17:02:06.850134Z","iopub.status.idle":"2026-01-28T17:02:31.972507Z","shell.execute_reply.started":"2026-01-28T17:02:06.850113Z","shell.execute_reply":"2026-01-28T17:02:31.971632Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Loading 2400 training samples...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2400/2400 [00:24<00:00, 97.37it/s] ","output_type":"stream"},{"name":"stdout","text":"Loaded 38087 data points from 2400 images\n\nDataset statistics:\nTotal points: 38087\nUnique images: 2400\n\nError bar statistics:\nMean top distance: 44.46px\nMean bottom distance: 42.32px\nPoints with error bars: 32816 (86.2%)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":7},{"id":"5628b18e","cell_type":"code","source":"# Extract features for all training points\nprint(\"Extracting features from training data...\")\n\nX_features = []\ny_top = []\ny_bottom = []\ncv_estimates = []\n\nfor idx, row in tqdm(train_df.iterrows(), total=len(train_df)):\n    features, cv_result = create_ml_features(row, CV_CONFIG)\n    \n    X_features.append(features)\n    y_top.append(row['topBarPixelDistance'])\n    y_bottom.append(row['bottomBarPixelDistance'])\n    cv_estimates.append(cv_result)\n\nX_train = np.array(X_features)\ny_train_top = np.array(y_top)\ny_train_bottom = np.array(y_bottom)\n\nprint(f\"\\nFeature matrix shape: {X_train.shape}\")\nprint(f\"Target top shape: {y_train_top.shape}\")\nprint(f\"Target bottom shape: {y_train_bottom.shape}\")\n\n# Store CV estimates in dataframe\ntrain_df['cv_top_dist'] = [cv['coarse_top_dist'] for cv in cv_estimates]\ntrain_df['cv_bottom_dist'] = [cv['coarse_bottom_dist'] for cv in cv_estimates]\ntrain_df['cv_confidence'] = [cv['confidence'] for cv in cv_estimates]","metadata":{"execution":{"iopub.status.busy":"2026-01-28T17:02:31.973525Z","iopub.execute_input":"2026-01-28T17:02:31.973822Z","iopub.status.idle":"2026-01-28T17:12:57.096884Z","shell.execute_reply.started":"2026-01-28T17:02:31.973793Z","shell.execute_reply":"2026-01-28T17:12:57.096165Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Extracting features from training data...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38087/38087 [10:25<00:00, 60.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nFeature matrix shape: (38087, 14)\nTarget top shape: (38087,)\nTarget bottom shape: (38087,)\n","output_type":"stream"}],"execution_count":8},{"id":"b7c9e180","cell_type":"code","source":"# Create comprehensive feature dataset for export\nfeature_names = [\n    # ROI Features (1â€“11)\n    'roi_mean_intensity', 'roi_std_intensity', 'roi_min_intensity', 'roi_max_intensity',\n    'roi_grad_y_mean', 'roi_grad_y_std',\n    'roi_edge_density',\n    'roi_center_col_mean', 'roi_center_col_std', 'roi_center_col_min', 'roi_center_col_max',\n    # CV Features (12â€“14)\n    'cv_coarse_top_dist', 'cv_coarse_bottom_dist', 'cv_confidence'\n]\n\n# Create feature dataframe\nfeature_df = pd.DataFrame(X_train, columns=feature_names)\n\n# Add metadata and targets\nfeature_df.insert(0, 'image_path', train_df['image_path'].values)\nfeature_df.insert(1, 'label_file', train_df['label_file'].values)\nfeature_df.insert(2, 'line_name', train_df['line_name'].values)\nfeature_df.insert(3, 'x', train_df['x'].values)\nfeature_df.insert(4, 'y', train_df['y'].values)\nfeature_df['target_top_dist'] = y_train_top\nfeature_df['target_bottom_dist'] = y_train_bottom\n\n# Save to CSV\nfeature_csv_path = os.path.join(OUTPUT_DIR, 'hybrid_features_dataset.csv')\nfeature_df.to_csv(feature_csv_path, index=False)\n\nprint(\"=\" * 80)\nprint(\"FEATURE DATASET EXPORTED\")\nprint(\"=\" * 80)\nprint(f\"File: {feature_csv_path}\")\nprint(f\"Shape: {feature_df.shape}\")\nprint(f\"Columns: {len(feature_df.columns)}\")\nprint(\"\\nDataset Preview:\")\nprint(feature_df.head(3).to_string())\nprint(\"\\n\" + \"=\" * 80)\nprint(\"\\nFeature Statistics:\")\nprint(feature_df[feature_names].describe().to_string())\nprint(\"=\" * 80)\n\n# Save feature descriptions\nfeature_descriptions = {\n    'Feature': feature_names,\n    'Category': (\n        ['ROI Intensity'] * 4 +\n        ['ROI Gradients'] * 2 +\n        ['ROI Edges'] * 1 +\n        ['ROI Center'] * 4 +\n        ['CV Coarse'] * 3\n    ),\n    'Description': [\n        'Mean pixel brightness in ROI',\n        'Std deviation of pixel brightness',\n        'Minimum pixel value',\n        'Maximum pixel value',\n        'Mean vertical gradient strength',\n        'Std deviation of vertical gradients',\n        'Percentage of edge pixels (Canny)',\n        'Mean brightness of center column',\n        'Std deviation of center column',\n        'Min value in center column',\n        'Max value in center column',\n        'CV-detected top error bar distance',\n        'CV-detected bottom error bar distance',\n        'CV detection confidence (0â€“1)'\n    ]\n}\n\nfeature_desc_df = pd.DataFrame(feature_descriptions)\nfeature_desc_path = os.path.join(OUTPUT_DIR, 'feature_descriptions.csv')\nfeature_desc_df.to_csv(feature_desc_path, index=False)\n\nprint(f\"\\nFeature descriptions saved to: {feature_desc_path}\")\nprint(\"\\nYou can now examine the feature dataset before model training!\")\nprint(\"This dataset shows exactly how CV features and ROI features combine.\")\n","metadata":{"execution":{"iopub.status.busy":"2026-01-28T17:12:57.097883Z","iopub.execute_input":"2026-01-28T17:12:57.098153Z","iopub.status.idle":"2026-01-28T17:12:57.939733Z","shell.execute_reply.started":"2026-01-28T17:12:57.098132Z","shell.execute_reply":"2026-01-28T17:12:57.939060Z"},"trusted":true},"outputs":[{"name":"stdout","text":"================================================================================\nFEATURE DATASET EXPORTED\n================================================================================\nFile: /kaggle/working/hybrid_features_dataset.csv\nShape: (38087, 21)\nColumns: 21\n\nDataset Preview:\n                                                                        image_path                                 label_file              line_name           x           y  roi_mean_intensity  roi_std_intensity  roi_min_intensity  roi_max_intensity  roi_grad_y_mean  roi_grad_y_std  roi_edge_density  roi_center_col_mean  roi_center_col_std  roi_center_col_min  roi_center_col_max  cv_coarse_top_dist  cv_coarse_bottom_dist  cv_confidence  target_top_dist  target_bottom_dist\n0  /kaggle/input/graph-plots/Train/images/001f3fd0-23eb-4371-a52a-41b9b71c36bf.png  001f3fd0-23eb-4371-a52a-41b9b71c36bf.json  Daratumumab_500mg_BID  176.957721   94.156410            246.2709          30.608733               99.0              255.0          14.0922       66.247937            0.0816               254.64            2.242855               239.0               255.0                11.0                   43.0           0.25       100.731681           52.716559\n1  /kaggle/input/graph-plots/Train/images/001f3fd0-23eb-4371-a52a-41b9b71c36bf.png  001f3fd0-23eb-4371-a52a-41b9b71c36bf.json  Daratumumab_500mg_BID  207.213200  105.508719            247.7590          28.784237               99.0              255.0          11.1176       59.443311            0.0703               254.64            2.242855               239.0               255.0                50.0                   16.0           0.10        98.189286           39.850114\n2  /kaggle/input/graph-plots/Train/images/001f3fd0-23eb-4371-a52a-41b9b71c36bf.png  001f3fd0-23eb-4371-a52a-41b9b71c36bf.json  Daratumumab_500mg_BID  298.259045  171.059432            249.4631          25.724666               99.0              255.0           6.9800       43.812155            0.0200               254.64            2.242855               239.0               255.0                 4.0                   39.0           0.20        46.989971           48.434765\n\n================================================================================\n\nFeature Statistics:\n       roi_mean_intensity  roi_std_intensity  roi_min_intensity  roi_max_intensity  roi_grad_y_mean  roi_grad_y_std  roi_edge_density  roi_center_col_mean  roi_center_col_std  roi_center_col_min  roi_center_col_max  cv_coarse_top_dist  cv_coarse_bottom_dist  cv_confidence\ncount        38087.000000       38087.000000       38087.000000       38087.000000     38087.000000    38087.000000      38087.000000         38087.000000        38087.000000        38087.000000        38087.000000        38087.000000           38087.000000   38087.000000\nmean           244.757179          31.181184          76.969937         254.675349        23.416535       89.663367          0.065625           234.685974           29.045118          121.427154          251.939848           21.954683              22.367133       0.489952\nstd              7.630603          13.242586          64.086516           1.576380        18.292367       53.975276          0.032312            30.935444           19.496104           75.626638           18.695364           20.437020              19.670129       0.380894\nmin             69.385600           1.638989           0.000000          79.000000         0.004000        0.173159          0.000000             0.000000            0.000000            0.000000            0.000000            0.000000               0.000000       0.000000\n25%            242.554750          21.145605           0.000000         255.000000        10.847800       51.497654          0.041900           234.550000           14.895434           59.000000          255.000000            0.000000               0.000000       0.000000\n50%            246.404800          29.996887          95.000000         255.000000        17.743000       72.069720          0.060108           245.320000           27.769739          130.000000          255.000000           18.000000              19.000000       0.600000\n75%            249.319400          39.101670         129.000000         255.000000        30.960800      109.563350          0.083800           250.810000           39.833441          170.000000          255.000000           45.000000              46.000000       0.900000\nmax            254.717400          95.301729         240.000000         255.000000       155.702300      317.202034          0.258900           255.000000          125.147543          255.000000          255.000000           50.000000              49.000000       1.000000\n================================================================================\n\nFeature descriptions saved to: /kaggle/working/feature_descriptions.csv\n\nYou can now examine the feature dataset before model training!\nThis dataset shows exactly how CV features and ROI features combine.\n","output_type":"stream"}],"execution_count":9},{"id":"a93f5a2c","cell_type":"markdown","source":"## 6a. Export Feature Dataset for Analysis\n\nBefore training, export the complete feature dataset for inspection and documentation.","metadata":{}},{"id":"12d2b33a","cell_type":"markdown","source":"## 7. Train Multiple Regression Models\n\n### Models to Compare:\n1. **Linear Regression** - Baseline\n2. **Ridge Regression** - L2 regularization\n3. **Random Forest** - Ensemble tree-based\n4. **Gradient Boosting** - Sequential boosting\n5. **MLP** - Small neural network","metadata":{}},{"id":"0ffdcad7","cell_type":"code","source":"# Standardize features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\n\n# Split for validation (80/20)\nfrom sklearn.model_selection import train_test_split\n\nX_tr, X_val, y_tr_top, y_val_top = train_test_split(\n    X_train_scaled, y_train_top, test_size=0.2, random_state=42\n)\n_, _, y_tr_bottom, y_val_bottom = train_test_split(\n    X_train_scaled, y_train_bottom, test_size=0.2, random_state=42\n)\n\nprint(f\"Training set: {X_tr.shape[0]} samples\")\nprint(f\"Validation set: {X_val.shape[0]} samples\")","metadata":{"execution":{"iopub.status.busy":"2026-01-28T17:12:57.942159Z","iopub.execute_input":"2026-01-28T17:12:57.942433Z","iopub.status.idle":"2026-01-28T17:12:57.965357Z","shell.execute_reply.started":"2026-01-28T17:12:57.942410Z","shell.execute_reply":"2026-01-28T17:12:57.964601Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Training set: 30469 samples\nValidation set: 7618 samples\n","output_type":"stream"}],"execution_count":10},{"id":"f2a611ad","cell_type":"code","source":"# Define models\nmodels = {\n    'Linear Regression': LinearRegression(),\n    'Ridge Regression': Ridge(alpha=1.0),\n    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),\n    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42),\n    'MLP': MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42, early_stopping=True)\n}\n\n# Train models for both top and bottom predictions\ntrained_models = {}\nresults = []\n\nprint(\"Training models...\\n\")\n\nfor name, model in models.items():\n    print(f\"Training {name}...\")\n    \n    # Clone models for top and bottom\n    from sklearn.base import clone\n    model_top = clone(model)\n    model_bottom = clone(model)\n    \n    # Train\n    model_top.fit(X_tr, y_tr_top)\n    model_bottom.fit(X_tr, y_tr_bottom)\n    \n    # Validate\n    pred_top = model_top.predict(X_val)\n    pred_bottom = model_bottom.predict(X_val)\n    \n    # Metrics\n    mae_top = mean_absolute_error(y_val_top, pred_top)\n    mae_bottom = mean_absolute_error(y_val_bottom, pred_bottom)\n    rmse_top = np.sqrt(mean_squared_error(y_val_top, pred_top))\n    rmse_bottom = np.sqrt(mean_squared_error(y_val_bottom, pred_bottom))\n    \n    # Store\n    trained_models[name] = {'top': model_top, 'bottom': model_bottom}\n    \n    results.append({\n        'Model': name,\n        'MAE Top': mae_top,\n        'MAE Bottom': mae_bottom,\n        'MAE Avg': (mae_top + mae_bottom) / 2,\n        'RMSE Top': rmse_top,\n        'RMSE Bottom': rmse_bottom,\n        'RMSE Avg': (rmse_top + rmse_bottom) / 2\n    })\n    \n    print(f\"  MAE Top: {mae_top:.2f}px, MAE Bottom: {mae_bottom:.2f}px\")\n    print(f\"  RMSE Top: {rmse_top:.2f}px, RMSE Bottom: {rmse_bottom:.2f}px\\n\")\n\n# Results table\nresults_df = pd.DataFrame(results)\nprint(\"\\n\" + \"=\"*80)\nprint(\"VALIDATION RESULTS\")\nprint(\"=\"*80)\nprint(results_df.to_string(index=False))\nprint(\"=\"*80)","metadata":{"execution":{"iopub.status.busy":"2026-01-28T17:12:57.966138Z","iopub.execute_input":"2026-01-28T17:12:57.966400Z","iopub.status.idle":"2026-01-28T17:13:55.023780Z","shell.execute_reply.started":"2026-01-28T17:12:57.966371Z","shell.execute_reply":"2026-01-28T17:13:55.023144Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Training models...\n\nTraining Linear Regression...\n  MAE Top: 32.51px, MAE Bottom: 29.89px\n  RMSE Top: 219.91px, RMSE Bottom: 223.70px\n\nTraining Ridge Regression...\n  MAE Top: 32.51px, MAE Bottom: 29.89px\n  RMSE Top: 219.91px, RMSE Bottom: 223.70px\n\nTraining Random Forest...\n  MAE Top: 33.83px, MAE Bottom: 32.46px\n  RMSE Top: 282.28px, RMSE Bottom: 239.53px\n\nTraining Gradient Boosting...\n  MAE Top: 35.71px, MAE Bottom: 31.83px\n  RMSE Top: 410.13px, RMSE Bottom: 213.29px\n\nTraining MLP...\n  MAE Top: 31.49px, MAE Bottom: 28.77px\n  RMSE Top: 220.14px, RMSE Bottom: 223.61px\n\n\n================================================================================\nVALIDATION RESULTS\n================================================================================\n            Model   MAE Top  MAE Bottom   MAE Avg   RMSE Top  RMSE Bottom   RMSE Avg\nLinear Regression 32.511818   29.894091 31.202954 219.906666   223.704247 221.805457\n Ridge Regression 32.511230   29.893631 31.202431 219.906582   223.704136 221.805359\n    Random Forest 33.832784   32.462999 33.147892 282.280307   239.526310 260.903308\nGradient Boosting 35.711747   31.826737 33.769242 410.130937   213.287677 311.709307\n              MLP 31.489044   28.770441 30.129742 220.142548   223.605047 221.873797\n================================================================================\n","output_type":"stream"}],"execution_count":11},{"id":"623dff97","cell_type":"markdown","source":"## 8. Hyperparameter Tuning\n\nTune the best performing model from above.","metadata":{}},{"id":"aae5b7b7","cell_type":"code","source":"# Select best model based on validation results\nbest_model_name = results_df.loc[results_df['MAE Avg'].idxmin(), 'Model']\nprint(f\"Best model: {best_model_name}\")\nprint(f\"Performing hyperparameter tuning...\\n\")\n\n# Hyperparameter grids\nparam_grids = {\n    'Ridge Regression': {\n        'alpha': [0.1, 1.0, 10.0, 100.0]\n    },\n    'Random Forest': {\n        'n_estimators': [50, 100, 200],\n        'max_depth': [5, 10, 15],\n        'min_samples_split': [2, 5, 10]\n    },\n    'Gradient Boosting': {\n        'n_estimators': [50, 100, 200],\n        'max_depth': [3, 5, 7],\n        'learning_rate': [0.01, 0.1, 0.2]\n    },\n    'MLP': {\n        'hidden_layer_sizes': [(32,), (64,), (64, 32), (128, 64)],\n        'alpha': [0.0001, 0.001, 0.01]\n    }\n}\n\nif best_model_name in param_grids:\n    # Grid search for top prediction\n    base_model = models[best_model_name]\n    grid_search = GridSearchCV(\n        base_model,\n        param_grids[best_model_name],\n        cv=3,\n        scoring='neg_mean_absolute_error',\n        n_jobs=-1,\n        verbose=1\n    )\n    \n    print(\"Tuning for top error bar prediction...\")\n    grid_search.fit(X_tr, y_tr_top)\n    best_model_top = grid_search.best_estimator_\n    \n    print(f\"Best params (top): {grid_search.best_params_}\")\n    print(f\"Best CV score (top): {-grid_search.best_score_:.2f}px MAE\\n\")\n    \n    # Grid search for bottom prediction\n    grid_search = GridSearchCV(\n        base_model,\n        param_grids[best_model_name],\n        cv=3,\n        scoring='neg_mean_absolute_error',\n        n_jobs=-1,\n        verbose=1\n    )\n    \n    print(\"Tuning for bottom error bar prediction...\")\n    grid_search.fit(X_tr, y_tr_bottom)\n    best_model_bottom = grid_search.best_estimator_\n    \n    print(f\"Best params (bottom): {grid_search.best_params_}\")\n    print(f\"Best CV score (bottom): {-grid_search.best_score_:.2f}px MAE\")\n    \n    # Update trained models\n    trained_models['Tuned ' + best_model_name] = {\n        'top': best_model_top,\n        'bottom': best_model_bottom\n    }\nelse:\n    print(f\"No tuning grid defined for {best_model_name}\")","metadata":{"execution":{"iopub.status.busy":"2026-01-28T17:13:55.024570Z","iopub.execute_input":"2026-01-28T17:13:55.024825Z","iopub.status.idle":"2026-01-28T17:15:06.555889Z","shell.execute_reply.started":"2026-01-28T17:13:55.024790Z","shell.execute_reply":"2026-01-28T17:15:06.555095Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Best model: MLP\nPerforming hyperparameter tuning...\n\nTuning for top error bar prediction...\nFitting 3 folds for each of 12 candidates, totalling 36 fits\nBest params (top): {'alpha': 0.0001, 'hidden_layer_sizes': (64, 32)}\nBest CV score (top): 31.99px MAE\n\nTuning for bottom error bar prediction...\nFitting 3 folds for each of 12 candidates, totalling 36 fits\nBest params (bottom): {'alpha': 0.01, 'hidden_layer_sizes': (64,)}\nBest CV score (bottom): 28.69px MAE\n","output_type":"stream"}],"execution_count":12},{"id":"881c693d","cell_type":"markdown","source":"## 9. Ablation Study\n\nCompare:\n- **CV Only** - Pure computer vision\n- **ML Only** - No CV features\n- **Hybrid** - CV + ML (full pipeline)","metadata":{}},{"id":"212c369f","cell_type":"code","source":"print(\"Running ablation study...\\n\")\n\nablation_results = []\n\n# 1. CV ONLY\n# Use CV estimates from validation split\nval_indices = train_test_split(\n    range(len(train_df)), test_size=0.2, random_state=42\n)[1]\n\ncv_pred_top = train_df.iloc[val_indices]['cv_top_dist'].values\ncv_pred_bottom = train_df.iloc[val_indices]['cv_bottom_dist'].values\n\nmae_cv_top = mean_absolute_error(y_val_top, cv_pred_top)\nmae_cv_bottom = mean_absolute_error(y_val_bottom, cv_pred_bottom)\nrmse_cv_top = np.sqrt(mean_squared_error(y_val_top, cv_pred_top))\nrmse_cv_bottom = np.sqrt(mean_squared_error(y_val_bottom, cv_pred_bottom))\n\nablation_results.append({\n    'Method': 'CV Only',\n    'MAE Top': mae_cv_top,\n    'MAE Bottom': mae_cv_bottom,\n    'MAE Avg': (mae_cv_top + mae_cv_bottom) / 2,\n    'RMSE Avg': (rmse_cv_top + rmse_cv_bottom) / 2\n})\n\nprint(f\"CV Only - MAE Top: {mae_cv_top:.2f}px, MAE Bottom: {mae_cv_bottom:.2f}px\\n\")\n\n# 2. ML ONLY (no CV features)\n# Use only first 11 features (ROI features, no CV estimates)\nX_tr_ml_only = X_tr[:, :11]\nX_val_ml_only = X_val[:, :11]\n\nml_only = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\nml_only_top = clone(ml_only)\nml_only_bottom = clone(ml_only)\n\nml_only_top.fit(X_tr_ml_only, y_tr_top)\nml_only_bottom.fit(X_tr_ml_only, y_tr_bottom)\n\nml_pred_top = ml_only_top.predict(X_val_ml_only)\nml_pred_bottom = ml_only_bottom.predict(X_val_ml_only)\n\nmae_ml_top = mean_absolute_error(y_val_top, ml_pred_top)\nmae_ml_bottom = mean_absolute_error(y_val_bottom, ml_pred_bottom)\nrmse_ml_top = np.sqrt(mean_squared_error(y_val_top, ml_pred_top))\nrmse_ml_bottom = np.sqrt(mean_squared_error(y_val_bottom, ml_pred_bottom))\n\nablation_results.append({\n    'Method': 'ML Only (no CV features)',\n    'MAE Top': mae_ml_top,\n    'MAE Bottom': mae_ml_bottom,\n    'MAE Avg': (mae_ml_top + mae_ml_bottom) / 2,\n    'RMSE Avg': (rmse_ml_top + rmse_ml_bottom) / 2\n})\n\nprint(f\"ML Only - MAE Top: {mae_ml_top:.2f}px, MAE Bottom: {mae_ml_bottom:.2f}px\\n\")\n\n# 3. HYBRID (full pipeline)\nbest_hybrid = trained_models[best_model_name]\nhybrid_pred_top = best_hybrid['top'].predict(X_val)\nhybrid_pred_bottom = best_hybrid['bottom'].predict(X_val)\n\nmae_hybrid_top = mean_absolute_error(y_val_top, hybrid_pred_top)\nmae_hybrid_bottom = mean_absolute_error(y_val_bottom, hybrid_pred_bottom)\nrmse_hybrid_top = np.sqrt(mean_squared_error(y_val_top, hybrid_pred_top))\nrmse_hybrid_bottom = np.sqrt(mean_squared_error(y_val_bottom, hybrid_pred_bottom))\n\nablation_results.append({\n    'Method': f'Hybrid (CV + {best_model_name})',\n    'MAE Top': mae_hybrid_top,\n    'MAE Bottom': mae_hybrid_bottom,\n    'MAE Avg': (mae_hybrid_top + mae_hybrid_bottom) / 2,\n    'RMSE Avg': (rmse_hybrid_top + rmse_hybrid_bottom) / 2\n})\n\nprint(f\"Hybrid - MAE Top: {mae_hybrid_top:.2f}px, MAE Bottom: {mae_hybrid_bottom:.2f}px\\n\")\n\n# Display ablation results\nablation_df = pd.DataFrame(ablation_results)\nprint(\"\\n\" + \"=\"*80)\nprint(\"ABLATION STUDY RESULTS\")\nprint(\"=\"*80)\nprint(ablation_df.to_string(index=False))\nprint(\"=\"*80)\n\n# Save ablation results\nablation_df.to_csv(os.path.join(OUTPUT_DIR, 'ablation_study.csv'), index=False)\nprint(f\"\\nAblation results saved to {OUTPUT_DIR}/ablation_study.csv\")","metadata":{"execution":{"iopub.status.busy":"2026-01-28T17:15:06.558307Z","iopub.execute_input":"2026-01-28T17:15:06.558577Z","iopub.status.idle":"2026-01-28T17:15:21.615867Z","shell.execute_reply.started":"2026-01-28T17:15:06.558552Z","shell.execute_reply":"2026-01-28T17:15:21.615275Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Running ablation study...\n\nCV Only - MAE Top: 29.34px, MAE Bottom: 27.12px\n\nML Only - MAE Top: 32.66px, MAE Bottom: 32.06px\n\nHybrid - MAE Top: 31.49px, MAE Bottom: 28.77px\n\n\n================================================================================\nABLATION STUDY RESULTS\n================================================================================\n                  Method   MAE Top  MAE Bottom   MAE Avg   RMSE Avg\n                 CV Only 29.341308   27.120453 28.230880 223.499885\nML Only (no CV features) 32.663262   32.062029 32.362646 183.587597\n       Hybrid (CV + MLP) 31.489044   28.770441 30.129742 221.873797\n================================================================================\n\nAblation results saved to /kaggle/working/ablation_study.csv\n","output_type":"stream"}],"execution_count":13},{"id":"00ffe295","cell_type":"markdown","source":"## 10. Select Final Model and Retrain on Full Training Data","metadata":{}},{"id":"77e82a7e","cell_type":"code","source":"# Use best hybrid model\nprint(f\"Final model: Hybrid (CV + {best_model_name})\\n\")\n\n# Retrain on full training data\nprint(\"Retraining on full training set...\")\n\nfinal_model_top = clone(trained_models[best_model_name]['top'])\nfinal_model_bottom = clone(trained_models[best_model_name]['bottom'])\n\nfinal_model_top.fit(X_train_scaled, y_train_top)\nfinal_model_bottom.fit(X_train_scaled, y_train_bottom)\n\nprint(\"Final models trained on full training set!\")","metadata":{"execution":{"iopub.status.busy":"2026-01-28T17:15:21.617218Z","iopub.execute_input":"2026-01-28T17:15:21.617714Z","iopub.status.idle":"2026-01-28T17:16:25.048522Z","shell.execute_reply.started":"2026-01-28T17:15:21.617678Z","shell.execute_reply":"2026-01-28T17:16:25.048017Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Final model: Hybrid (CV + MLP)\n\nRetraining on full training set...\nFinal models trained on full training set!\n","output_type":"stream"}],"execution_count":14},{"id":"f9125901","cell_type":"markdown","source":"## 11. Evaluation Functions","metadata":{}},{"id":"822b1188","cell_type":"code","source":"def calculate_metrics(y_true_top, y_true_bottom, y_pred_top, y_pred_bottom):\n    \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n    \n    # Absolute errors\n    errors_top = np.abs(y_true_top - y_pred_top)\n    errors_bottom = np.abs(y_true_bottom - y_pred_bottom)\n    errors_mean = (errors_top + errors_bottom) / 2\n    \n    # Accuracy at thresholds\n    acc_5px = np.mean(errors_mean <= 5) * 100\n    acc_10px = np.mean(errors_mean <= 10) * 100\n    acc_20px = np.mean(errors_mean <= 20) * 100\n    \n    metrics = {\n        'num_points': len(y_true_top),\n        'mean_top_error': np.mean(errors_top),\n        'mean_bottom_error': np.mean(errors_bottom),\n        'mean_overall_error': np.mean(errors_mean),\n        'median_top_error': np.median(errors_top),\n        'median_bottom_error': np.median(errors_bottom),\n        'median_overall_error': np.median(errors_mean),\n        'rmse_top': np.sqrt(mean_squared_error(y_true_top, y_pred_top)),\n        'rmse_bottom': np.sqrt(mean_squared_error(y_true_bottom, y_pred_bottom)),\n        'rmse_overall': np.sqrt(mean_squared_error(\n            np.concatenate([y_true_top, y_true_bottom]),\n            np.concatenate([y_pred_top, y_pred_bottom])\n        )),\n        'accuracy_5px': acc_5px,\n        'accuracy_10px': acc_10px,\n        'accuracy_20px': acc_20px,\n        'std_top_error': np.std(errors_top),\n        'std_bottom_error': np.std(errors_bottom),\n        'max_top_error': np.max(errors_top),\n        'max_bottom_error': np.max(errors_bottom)\n    }\n    \n    return metrics\n\ndef print_metrics(metrics, title=\"METRICS\"):\n    \"\"\"Pretty print metrics\"\"\"\n    print(\"\\n\" + \"=\"*80)\n    print(title)\n    print(\"=\"*80)\n    print(f\"Total Points: {metrics['num_points']}\")\n    print(f\"\\nMean Errors:\")\n    print(f\"  Top Error:     {metrics['mean_top_error']:.2f}px\")\n    print(f\"  Bottom Error:  {metrics['mean_bottom_error']:.2f}px\")\n    print(f\"  Overall Error: {metrics['mean_overall_error']:.2f}px\")\n    print(f\"\\nMedian Errors:\")\n    print(f\"  Top Error:     {metrics['median_top_error']:.2f}px\")\n    print(f\"  Bottom Error:  {metrics['median_bottom_error']:.2f}px\")\n    print(f\"  Overall Error: {metrics['median_overall_error']:.2f}px\")\n    print(f\"\\nRMSE:\")\n    print(f\"  Top:     {metrics['rmse_top']:.2f}px\")\n    print(f\"  Bottom:  {metrics['rmse_bottom']:.2f}px\")\n    print(f\"  Overall: {metrics['rmse_overall']:.2f}px\")\n    print(f\"\\nAccuracy @ Threshold:\")\n    print(f\"  Within 5px:  {metrics['accuracy_5px']:.1f}%\")\n    print(f\"  Within 10px: {metrics['accuracy_10px']:.1f}%\")\n    print(f\"  Within 20px: {metrics['accuracy_20px']:.1f}%\")\n    print(\"=\"*80)\n\nprint(\"Evaluation functions defined!\")","metadata":{"execution":{"iopub.status.busy":"2026-01-28T17:16:25.050673Z","iopub.execute_input":"2026-01-28T17:16:25.050965Z","iopub.status.idle":"2026-01-28T17:16:25.066287Z","shell.execute_reply.started":"2026-01-28T17:16:25.050938Z","shell.execute_reply":"2026-01-28T17:16:25.065666Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Evaluation functions defined!\n","output_type":"stream"}],"execution_count":15},{"id":"f501d87b","cell_type":"markdown","source":"## 12. Validation Set Evaluation","metadata":{}},{"id":"60c53225","cell_type":"code","source":"# Evaluate on validation set\nval_pred_top = final_model_top.predict(X_val)\nval_pred_bottom = final_model_bottom.predict(X_val)\n\nval_metrics = calculate_metrics(y_val_top, y_val_bottom, val_pred_top, val_pred_bottom)\nprint_metrics(val_metrics, \"VALIDATION SET RESULTS (Hybrid CV+ML)\")","metadata":{"execution":{"iopub.status.busy":"2026-01-28T17:16:25.068318Z","iopub.execute_input":"2026-01-28T17:16:25.069206Z","iopub.status.idle":"2026-01-28T17:16:25.098625Z","shell.execute_reply.started":"2026-01-28T17:16:25.069179Z","shell.execute_reply":"2026-01-28T17:16:25.098143Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n================================================================================\nVALIDATION SET RESULTS (Hybrid CV+ML)\n================================================================================\nTotal Points: 7618\n\nMean Errors:\n  Top Error:     30.58px\n  Bottom Error:  29.86px\n  Overall Error: 30.22px\n\nMedian Errors:\n  Top Error:     15.06px\n  Bottom Error:  14.67px\n  Overall Error: 16.14px\n\nRMSE:\n  Top:     217.75px\n  Bottom:  216.64px\n  Overall: 217.20px\n\nAccuracy @ Threshold:\n  Within 5px:  12.2%\n  Within 10px: 31.5%\n  Within 20px: 59.1%\n================================================================================\n","output_type":"stream"}],"execution_count":16},{"id":"d3ed7d13","cell_type":"markdown","source":"## 13. Save Models and Results","metadata":{}},{"id":"5433caea","cell_type":"code","source":"import pickle\n\n# Save models\nmodels_to_save = {\n    'model_top': final_model_top,\n    'model_bottom': final_model_bottom,\n    'scaler': scaler,\n    'config': CV_CONFIG,\n    'best_model_name': best_model_name\n}\n\nwith open(os.path.join(OUTPUT_DIR, 'hybrid_models.pkl'), 'wb') as f:\n    pickle.dump(models_to_save, f)\n\nprint(f\"Models saved to {OUTPUT_DIR}/hybrid_models.pkl\")\n\n# Save validation metrics\nval_metrics_df = pd.DataFrame([val_metrics])\nval_metrics_df.to_csv(os.path.join(OUTPUT_DIR, 'validation_metrics.csv'), index=False)\n\nprint(f\"Validation metrics saved to {OUTPUT_DIR}/validation_metrics.csv\")","metadata":{"execution":{"iopub.status.busy":"2026-01-28T17:16:25.099260Z","iopub.execute_input":"2026-01-28T17:16:25.099523Z","iopub.status.idle":"2026-01-28T17:16:25.112241Z","shell.execute_reply.started":"2026-01-28T17:16:25.099493Z","shell.execute_reply":"2026-01-28T17:16:25.111449Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Models saved to /kaggle/working/hybrid_models.pkl\nValidation metrics saved to /kaggle/working/validation_metrics.csv\n","output_type":"stream"}],"execution_count":17},{"id":"c64bcdb7","cell_type":"markdown","source":"## 14. Test Set Prediction Function\n\nDefine the prediction function that will be used for test set evaluation.","metadata":{}},{"id":"1e8c9123","cell_type":"code","source":"def predict_error_bars(image_path: str, data_points: List[Dict], model_top, model_bottom, scaler, config: Dict) -> List[Dict]:\n    \"\"\"\n    Predict error bars for a list of data points in an image.\n    \"\"\"\n    predictions = []\n    \n    for point in data_points:\n        x = point['x']\n        y = point['y']\n        \n        # Extract features\n        cv_result = detect_error_bar_cv(image_path, x, y, config)\n        roi_features = extract_roi_features(image_path, x, y, config['roi_size'])\n        \n        # Combine features\n        features = np.concatenate([\n            roi_features,\n            [cv_result['coarse_top_dist'],\n             cv_result['coarse_bottom_dist'],\n             cv_result['confidence']]\n        ])\n        \n        # Scale and predict\n        features_scaled = scaler.transform(features.reshape(1, -1))\n        pred_top = model_top.predict(features_scaled)[0]\n        pred_bottom = model_bottom.predict(features_scaled)[0]\n        \n        # Ensure non-negative\n        pred_top = max(0, pred_top)\n        pred_bottom = max(0, pred_bottom)\n        \n        predictions.append({\n            'x': x,\n            'y': y,\n            'topBarPixelDistance': float(pred_top),\n            'bottomBarPixelDistance': float(pred_bottom),\n            'deviationPixelDistance': float(max(pred_top, pred_bottom)),\n            'label': point.get('label', '')\n        })\n    \n    return predictions\n\nprint(\"Test prediction function defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T17:16:25.114320Z","iopub.execute_input":"2026-01-28T17:16:25.114538Z","iopub.status.idle":"2026-01-28T17:16:25.126692Z","shell.execute_reply.started":"2026-01-28T17:16:25.114517Z","shell.execute_reply":"2026-01-28T17:16:25.126038Z"}},"outputs":[{"name":"stdout","text":"Test prediction function defined!\n","output_type":"stream"}],"execution_count":18},{"id":"60d2cd8f","cell_type":"markdown","source":"## 15. Process Test Set (600 samples)\n\nEvaluate the best trained model on the test set.","metadata":{}},{"id":"2a626467","cell_type":"code","source":"# Process test set with 600-sample limit\nprint(\"Processing test set (600 samples)...\\n\")\n\n# Initialize all required variables\nall_test_predictions = {}\ntest_detailed_results = []\nall_model_predictions = {}\nall_model_test_metrics = {}\n\ntest_files = sorted([f for f in os.listdir(TEST_INPUT_LABELS) if f.endswith('.json')])\n\n# Limit to 600 samples for evaluation\nimport random\nrandom.seed(42)\nif len(test_files) > 600:\n    test_files = random.sample(test_files, 600)\n    print(f\"Randomly selected 600 files from {len(os.listdir(TEST_INPUT_LABELS))} total test files\")\nelse:\n    print(f\"Using all {len(test_files)} test files (less than 600)\")\n\ntest_processed = 0\ntest_failed = 0\n\nfor test_file in tqdm(test_files):\n    try:\n        # Load input\n        input_path = os.path.join(TEST_INPUT_LABELS, test_file)\n        with open(input_path, 'r') as f:\n            input_data = json.load(f)\n        \n        image_file = input_data.get('image_file', test_file.replace('.json', '.png'))\n        image_path = os.path.join(TEST_IMAGES, image_file)\n        \n        if not os.path.exists(image_path):\n            test_failed += 1\n            continue\n        \n        # Predict for each line\n        predictions = []\n        \n        for line_data in input_data.get('data_points', []):\n            line_name = line_data.get('lineName', '')\n            points = line_data.get('points', [])\n            \n            # Predict error bars\n            pred_points = predict_error_bars(\n                image_path, points, \n                final_model_top, final_model_bottom, \n                scaler, CV_CONFIG\n            )\n            \n            predictions.append({\n                'label': {'lineName': line_name},\n                'points': pred_points\n            })\n        \n        # Store predictions\n        all_test_predictions[test_file] = {\n            'image_file': image_file,\n            'predictions': predictions\n        }\n        \n        # Evaluate against ground truth\n        gt_path = os.path.join(TEST_GROUND_TRUTH, test_file)\n        if os.path.exists(gt_path):\n            with open(gt_path, 'r') as f:\n                gt_data = json.load(f)\n            \n            # Calculate errors for this image\n            image_errors_top = []\n            image_errors_bottom = []\n            \n            for pred_line in predictions:\n                # Find matching ground truth line\n                gt_line = None\n                for gt in gt_data:\n                    if gt.get('label', {}).get('lineName') == pred_line.get('label', {}).get('lineName'):\n                        gt_line = gt\n                        break\n                \n                if gt_line is None:\n                    continue\n                \n                pred_points = [p for p in pred_line['points'] if p.get('label', '') not in ['xmin', 'xmax', 'ymin', 'ymax']]\n                gt_points = [p for p in gt_line['points'] if p.get('label', '') not in ['xmin', 'xmax', 'ymin', 'ymax']]\n                \n                for pred_pt, gt_pt in zip(pred_points, gt_points):\n                    image_errors_top.append(abs(pred_pt['topBarPixelDistance'] - gt_pt.get('topBarPixelDistance', 0)))\n                    image_errors_bottom.append(abs(pred_pt['bottomBarPixelDistance'] - gt_pt.get('bottomBarPixelDistance', 0)))\n            \n            if image_errors_top:\n                test_detailed_results.append({\n                    'image_file': image_file,\n                    'num_points': len(image_errors_top),\n                    'mean_top_error': np.mean(image_errors_top),\n                    'mean_bottom_error': np.mean(image_errors_bottom),\n                    'mean_overall_error': np.mean(image_errors_top + image_errors_bottom)\n                })\n        \n        test_processed += 1\n        \n    except Exception as e:\n        test_failed += 1\n        if test_failed <= 5:\n            print(f\"Error processing {test_file}: {e}\")\n\nprint(f\"\\n{'='*80}\")\nprint(f\"TEST SET PROCESSING COMPLETE (600 SAMPLES)\")\nprint(f\"{'='*80}\")\nprint(f\"Total selected: {len(test_files)} files\")\nprint(f\"Processed: {test_processed} files\")\nprint(f\"Failed: {test_failed} files\")\nprint(f\"{'='*80}\")","metadata":{"execution":{"iopub.status.busy":"2026-01-28T17:16:41.824443Z","iopub.execute_input":"2026-01-28T17:16:41.825131Z","iopub.status.idle":"2026-01-28T17:19:41.408203Z","shell.execute_reply.started":"2026-01-28T17:16:41.825105Z","shell.execute_reply":"2026-01-28T17:19:41.407548Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Processing test set (600 samples)...\n\nUsing all 600 test files (less than 600)\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [02:59<00:00,  3.34it/s]","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\nTEST SET PROCESSING COMPLETE (600 SAMPLES)\n================================================================================\nTotal selected: 600 files\nProcessed: 600 files\nFailed: 0 files\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":20},{"id":"07dc78de","cell_type":"code","source":"# Generate predictions for ALL models on the same 600-sample test set\nprint(\"Generating predictions for all models on 600-sample test set...\\n\")\n\n# Add CV-only baseline\ntrained_models['CV Only (Baseline)'] = None  # Special marker for CV-only\n\nfor model_name in tqdm(trained_models.keys(), desc=\"Processing models\"):\n    print(f\"\\n{'='*80}\")\n    print(f\"MODEL: {model_name}\")\n    print(f\"{'='*80}\")\n    \n    model_predictions = {}\n    model_test_results = []\n    test_processed = 0\n    test_failed = 0\n    \n    # Use the same test_files subset (600 samples)\n    for test_file in test_files:\n        try:\n            # Load input\n            input_path = os.path.join(TEST_INPUT_LABELS, test_file)\n            with open(input_path, 'r') as f:\n                input_data = json.load(f)\n            \n            image_file = input_data.get('image_file', test_file.replace('.json', '.png'))\n            image_path = os.path.join(TEST_IMAGES, image_file)\n            \n            if not os.path.exists(image_path):\n                test_failed += 1\n                continue\n            \n            # Predict for each line\n            predictions = []\n            \n            for line_data in input_data.get('data_points', []):\n                line_name = line_data.get('lineName', '')\n                points = line_data.get('points', [])\n                \n                # Predict based on model type\n                if model_name == 'CV Only (Baseline)':\n                    # Use CV estimates directly\n                    pred_points = []\n                    for point in points:\n                        cv_result = detect_error_bar_cv(image_path, point['x'], point['y'], CV_CONFIG)\n                        pred_points.append({\n                            'x': point['x'],\n                            'y': point['y'],\n                            'topBarPixelDistance': float(cv_result['coarse_top_dist']),\n                            'bottomBarPixelDistance': float(cv_result['coarse_bottom_dist']),\n                            'deviationPixelDistance': float(max(cv_result['coarse_top_dist'], cv_result['coarse_bottom_dist'])),\n                            'label': point.get('label', '')\n                        })\n                else:\n                    # Use ML model\n                    model_top = trained_models[model_name]['top']\n                    model_bottom = trained_models[model_name]['bottom']\n                    pred_points = predict_error_bars(\n                        image_path, points, \n                        model_top, model_bottom, \n                        scaler, CV_CONFIG\n                    )\n                \n                predictions.append({\n                    'label': {'lineName': line_name},\n                    'points': pred_points\n                })\n            \n            # Store predictions\n            model_predictions[test_file] = {\n                'image_file': image_file,\n                'predictions': predictions\n            }\n            \n            # Evaluate against ground truth\n            gt_path = os.path.join(TEST_GROUND_TRUTH, test_file)\n            if os.path.exists(gt_path):\n                with open(gt_path, 'r') as f:\n                    gt_data = json.load(f)\n                \n                image_errors_top = []\n                image_errors_bottom = []\n                \n                for pred_line in predictions:\n                    gt_line = None\n                    for gt in gt_data:\n                        if gt.get('label', {}).get('lineName') == pred_line.get('label', {}).get('lineName'):\n                            gt_line = gt\n                            break\n                    \n                    if gt_line is None:\n                        continue\n                    \n                    pred_points = [p for p in pred_line['points'] if p.get('label', '') not in ['xmin', 'xmax', 'ymin', 'ymax']]\n                    gt_points = [p for p in gt_line['points'] if p.get('label', '') not in ['xmin', 'xmax', 'ymin', 'ymax']]\n                    \n                    for pred_pt, gt_pt in zip(pred_points, gt_points):\n                        image_errors_top.append(abs(pred_pt['topBarPixelDistance'] - gt_pt.get('topBarPixelDistance', 0)))\n                        image_errors_bottom.append(abs(pred_pt['bottomBarPixelDistance'] - gt_pt.get('bottomBarPixelDistance', 0)))\n                \n                if image_errors_top:\n                    model_test_results.append({\n                        'image_file': image_file,\n                        'num_points': len(image_errors_top),\n                        'mean_top_error': np.mean(image_errors_top),\n                        'mean_bottom_error': np.mean(image_errors_bottom),\n                        'mean_overall_error': np.mean(image_errors_top + image_errors_bottom)\n                    })\n            \n            test_processed += 1\n            \n        except Exception as e:\n            test_failed += 1\n            if test_failed <= 3:\n                print(f\"Error: {test_file}: {e}\")\n    \n    # Calculate model metrics\n    if model_test_results:\n        all_test_top_errors = []\n        all_test_bottom_errors = []\n        \n        for result in model_test_results:\n            all_test_top_errors.extend([result['mean_top_error']] * result['num_points'])\n            all_test_bottom_errors.extend([result['mean_bottom_error']] * result['num_points'])\n        \n        all_test_mean_errors = [(t + b) / 2 for t, b in zip(all_test_top_errors, all_test_bottom_errors)]\n        \n        model_metrics = {\n            'model_name': model_name,\n            'num_images': len(model_test_results),\n            'num_points': sum(r['num_points'] for r in model_test_results),\n            'mean_top_error': np.mean(all_test_top_errors),\n            'mean_bottom_error': np.mean(all_test_bottom_errors),\n            'mean_overall_error': np.mean(all_test_mean_errors),\n            'median_top_error': np.median(all_test_top_errors),\n            'median_bottom_error': np.median(all_test_bottom_errors),\n            'median_overall_error': np.median(all_test_mean_errors),\n            'rmse_top': np.sqrt(np.mean(np.array(all_test_top_errors)**2)),\n            'rmse_bottom': np.sqrt(np.mean(np.array(all_test_bottom_errors)**2)),\n            'rmse_overall': np.sqrt(np.mean(np.array(all_test_mean_errors)**2)),\n            'accuracy_5px': np.mean(np.array(all_test_mean_errors) <= 5) * 100,\n            'accuracy_10px': np.mean(np.array(all_test_mean_errors) <= 10) * 100,\n            'accuracy_20px': np.mean(np.array(all_test_mean_errors) <= 20) * 100,\n            'std_top_error': np.std(all_test_top_errors),\n            'std_bottom_error': np.std(all_test_bottom_errors)\n        }\n        \n        all_model_test_metrics[model_name] = model_metrics\n        all_model_predictions[model_name] = model_predictions\n        \n        print(f\"\\nProcessed: {test_processed} images\")\n        print(f\"Mean Error: {model_metrics['mean_overall_error']:.2f}px\")\n        print(f\"Accuracy@10px: {model_metrics['accuracy_10px']:.1f}%\")\n\n\nprint(f\"\\n{'='*80}\")\nprint(f\"ALL MODELS PROCESSED ON 600-SAMPLE TEST SET\")\nprint(f\"{'='*80}\")","metadata":{"execution":{"iopub.status.busy":"2026-01-28T17:19:41.409619Z","iopub.execute_input":"2026-01-28T17:19:41.409878Z","iopub.status.idle":"2026-01-28T17:46:11.678156Z","shell.execute_reply.started":"2026-01-28T17:19:41.409847Z","shell.execute_reply":"2026-01-28T17:46:11.677448Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Generating predictions for all models on 600-sample test set...\n\n","output_type":"stream"},{"name":"stderr","text":"Processing models:   0%|          | 0/7 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\nMODEL: Linear Regression\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"Processing models:  14%|â–ˆâ–        | 1/7 [02:47<16:46, 167.83s/it]","output_type":"stream"},{"name":"stdout","text":"\nProcessed: 600 images\nMean Error: 24.79px\nAccuracy@10px: 1.0%\n\n================================================================================\nMODEL: Ridge Regression\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"Processing models:  29%|â–ˆâ–ˆâ–Š       | 2/7 [05:36<14:01, 168.27s/it]","output_type":"stream"},{"name":"stdout","text":"\nProcessed: 600 images\nMean Error: 24.79px\nAccuracy@10px: 1.0%\n\n================================================================================\nMODEL: Random Forest\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"Processing models:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [16:24<25:50, 387.54s/it]","output_type":"stream"},{"name":"stdout","text":"\nProcessed: 600 images\nMean Error: 30.26px\nAccuracy@10px: 8.9%\n\n================================================================================\nMODEL: Gradient Boosting\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"Processing models:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [19:22<15:14, 304.71s/it]","output_type":"stream"},{"name":"stdout","text":"\nProcessed: 600 images\nMean Error: 27.67px\nAccuracy@10px: 6.3%\n\n================================================================================\nMODEL: MLP\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"Processing models:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 5/7 [22:15<08:34, 257.18s/it]","output_type":"stream"},{"name":"stdout","text":"\nProcessed: 600 images\nMean Error: 23.93px\nAccuracy@10px: 2.7%\n\n================================================================================\nMODEL: Tuned MLP\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"Processing models:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [25:08<03:48, 228.40s/it]","output_type":"stream"},{"name":"stdout","text":"\nProcessed: 600 images\nMean Error: 24.04px\nAccuracy@10px: 2.3%\n\n================================================================================\nMODEL: CV Only (Baseline)\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"Processing models: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [26:30<00:00, 227.18s/it]","output_type":"stream"},{"name":"stdout","text":"\nProcessed: 600 images\nMean Error: 21.07px\nAccuracy@10px: 10.5%\n\n================================================================================\nALL MODELS PROCESSED ON 600-SAMPLE TEST SET\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":21},{"id":"005f2766","cell_type":"code","source":"# FINAL COMPREHENSIVE COMPARISON TABLE (600 Test Samples)\nprint(\"\\n\" + \"=\"*120)\nprint(\"FINAL MODEL COMPARISON - ALL APPROACHES (600 TEST SAMPLES)\")\nprint(\"=\"*120)\n\ncomparison_data = []\n\nfor model_name, metrics in all_model_test_metrics.items():\n    comparison_data.append({\n        'Approach': model_name,\n        'Images': metrics['num_images'],\n        'Points': metrics['num_points'],\n        'Mean Error (px)': round(metrics['mean_overall_error'], 2),\n        'Median Error (px)': round(metrics['median_overall_error'], 2),\n        'RMSE (px)': round(metrics['rmse_overall'], 2),\n        'Std Dev (px)': round((metrics['std_top_error'] + metrics['std_bottom_error']) / 2, 2),\n        'Acc@5px (%)': round(metrics['accuracy_5px'], 1),\n        'Acc@10px (%)': round(metrics['accuracy_10px'], 1),\n        'Acc@20px (%)': round(metrics['accuracy_20px'], 1)\n    })\n\ncomparison_df = pd.DataFrame(comparison_data)\n\n# Sort by mean error (best first)\ncomparison_df = comparison_df.sort_values('Mean Error (px)')\n\n# Add rank column\ncomparison_df.insert(0, 'Rank', range(1, len(comparison_df) + 1))\n\nprint(\"\\n\" + comparison_df.to_string(index=False))\nprint(\"\\n\" + \"=\"*120)\n\n# Save comprehensive comparison table\ncomparison_csv = os.path.join(OUTPUT_DIR, 'final_model_comparison_600samples.csv')\ncomparison_df.to_csv(comparison_csv, index=False)\nprint(f\"\\nFinal comparison table saved to: {comparison_csv}\")\n\n# Identify best model\nbest_model_name = comparison_df.iloc[0]['Approach']\nbest_model_error = comparison_df.iloc[0]['Mean Error (px)']\n\nprint(f\"\\n{'='*120}\")\nprint(f\"ðŸ† BEST MODEL: {best_model_name}\")\nprint(f\"Mean Overall Error: {best_model_error:.2f}px\")\nprint(f\"{'='*120}\")\n\n# Performance improvement analysis\nif 'CV Only (Baseline)' in all_model_test_metrics:\n    baseline_error = all_model_test_metrics['CV Only (Baseline)']['mean_overall_error']\n    \n    print(f\"\\n{'='*120}\")\n    print(\"IMPROVEMENT OVER CV BASELINE\")\n    print(\"=\"*120)\n    \n    improvement_data = []\n    for model_name, metrics in all_model_test_metrics.items():\n        if model_name != 'CV Only (Baseline)':\n            improvement_pct = ((baseline_error - metrics['mean_overall_error']) / baseline_error) * 100\n            improvement_px = baseline_error - metrics['mean_overall_error']\n            improvement_data.append({\n                'Approach': model_name,\n                'Mean Error (px)': round(metrics['mean_overall_error'], 2),\n                'Baseline Error (px)': round(baseline_error, 2),\n                'Improvement (%)': round(improvement_pct, 1),\n                'Error Reduction (px)': round(improvement_px, 2)\n            })\n    \n    improvement_df = pd.DataFrame(improvement_data)\n    improvement_df = improvement_df.sort_values('Improvement (%)', ascending=False)\n    print(\"\\n\" + improvement_df.to_string(index=False))\n    print(\"=\"*120)\n    \n    # Save improvement table\n    improvement_csv = os.path.join(OUTPUT_DIR, 'improvement_over_baseline_600samples.csv')\n    improvement_df.to_csv(improvement_csv, index=False)\n    print(f\"\\nImprovement analysis saved to: {improvement_csv}\")\n\n# Summary statistics\nprint(f\"\\n{'='*120}\")\nprint(\"SUMMARY STATISTICS\")\nprint(\"=\"*120)\nprint(f\"Test Set Size: 600 samples\")\nprint(f\"Total Models Evaluated: {len(comparison_df)}\")\nprint(f\"\\nBest Performance:\")\nprint(f\"  Model: {comparison_df.iloc[0]['Approach']}\")\nprint(f\"  Mean Error: {comparison_df.iloc[0]['Mean Error (px)']:.2f}px\")\nprint(f\"  Accuracy@10px: {comparison_df.iloc[0]['Acc@10px (%)']:.1f}%\")\nprint(f\"\\nWorst Performance:\")\nprint(f\"  Model: {comparison_df.iloc[-1]['Approach']}\")\nprint(f\"  Mean Error: {comparison_df.iloc[-1]['Mean Error (px)']:.2f}px\")\nprint(f\"  Accuracy@10px: {comparison_df.iloc[-1]['Acc@10px (%)']:.1f}%\")\nprint(f\"\\nAverage Across All Models:\")\nprint(f\"  Mean Error: {comparison_df['Mean Error (px)'].mean():.2f}px\")\nprint(f\"  RMSE: {comparison_df['RMSE (px)'].mean():.2f}px\")\nprint(f\"  Accuracy@10px: {comparison_df['Acc@10px (%)'].mean():.1f}%\")\nprint(\"=\"*120)\n\nprint(\"\\nâœ… FINAL COMPARISON COMPLETE - ALL APPROACHES EVALUATED ON 600 TEST SAMPLES\")\nprint(\"âœ… Results saved to CSV files for documentation\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T17:46:11.679140Z","iopub.execute_input":"2026-01-28T17:46:11.679387Z","iopub.status.idle":"2026-01-28T17:46:11.704335Z","shell.execute_reply.started":"2026-01-28T17:46:11.679366Z","shell.execute_reply":"2026-01-28T17:46:11.703488Z"}},"outputs":[{"name":"stdout","text":"\n========================================================================================================================\nFINAL MODEL COMPARISON - ALL APPROACHES (600 TEST SAMPLES)\n========================================================================================================================\n\n Rank           Approach  Images  Points  Mean Error (px)  Median Error (px)  RMSE (px)  Std Dev (px)  Acc@5px (%)  Acc@10px (%)  Acc@20px (%)\n    1 CV Only (Baseline)     600   10229            21.07              15.54      37.74         31.84          0.5          10.5          72.7\n    2                MLP     600   10229            23.93              19.68      36.36         27.89          0.0           2.7          52.3\n    3          Tuned MLP     600   10229            24.04              19.78      36.26         27.79          0.1           2.3          51.0\n    4  Linear Regression     600   10229            24.79              20.65      36.70         27.53          0.1           1.0          44.2\n    5   Ridge Regression     600   10229            24.79              20.65      36.70         27.53          0.1           1.0          44.2\n    6  Gradient Boosting     600   10229            27.67              16.40      56.71         60.02          0.1           6.3          65.3\n    7      Random Forest     600   10229            30.26              16.65      70.28         71.88          0.4           8.9          67.0\n\n========================================================================================================================\n\nFinal comparison table saved to: /kaggle/working/final_model_comparison_600samples.csv\n\n========================================================================================================================\nðŸ† BEST MODEL: CV Only (Baseline)\nMean Overall Error: 21.07px\n========================================================================================================================\n\n========================================================================================================================\nIMPROVEMENT OVER CV BASELINE\n========================================================================================================================\n\n         Approach  Mean Error (px)  Baseline Error (px)  Improvement (%)  Error Reduction (px)\n              MLP            23.93                21.07            -13.5                 -2.85\n        Tuned MLP            24.04                21.07            -14.1                 -2.96\n Ridge Regression            24.79                21.07            -17.7                 -3.72\nLinear Regression            24.79                21.07            -17.7                 -3.72\nGradient Boosting            27.67                21.07            -31.3                 -6.59\n    Random Forest            30.26                21.07            -43.6                 -9.18\n========================================================================================================================\n\nImprovement analysis saved to: /kaggle/working/improvement_over_baseline_600samples.csv\n\n========================================================================================================================\nSUMMARY STATISTICS\n========================================================================================================================\nTest Set Size: 600 samples\nTotal Models Evaluated: 7\n\nBest Performance:\n  Model: CV Only (Baseline)\n  Mean Error: 21.07px\n  Accuracy@10px: 10.5%\n\nWorst Performance:\n  Model: Random Forest\n  Mean Error: 30.26px\n  Accuracy@10px: 8.9%\n\nAverage Across All Models:\n  Mean Error: 25.22px\n  RMSE: 44.39px\n  Accuracy@10px: 4.7%\n========================================================================================================================\n\nâœ… FINAL COMPARISON COMPLETE - ALL APPROACHES EVALUATED ON 600 TEST SAMPLES\nâœ… Results saved to CSV files for documentation\n","output_type":"stream"}],"execution_count":22},{"id":"df59ebc2","cell_type":"markdown","source":"## 17. Final Model Comparison Table\n\nCompare all approaches and identify the best performing model.","metadata":{}},{"id":"fcd6ef71","cell_type":"code","source":"from datetime import datetime\nimport zipfile\n\n# Export BEST model predictions only\nprint(f\"\\nExporting predictions for BEST model: {best_model_name}\\n\")\n\n# Get predictions for best model\nbest_predictions = all_model_predictions[best_model_name]\n\n# Create predictions directory\npred_dir = os.path.join(OUTPUT_DIR, \"predictions\")\nos.makedirs(pred_dir, exist_ok=True)\n\n# Save JSON files\nsaved_count = 0\nfor test_file, pred_data in best_predictions.items():\n    output_data = {\n        'image_file': pred_data['image_file'],\n        'model': best_model_name,\n        'data_points': pred_data['predictions']\n    }\n    \n    output_path = os.path.join(pred_dir, test_file)\n    with open(output_path, 'w') as f:\n        json.dump(output_data, f, indent=2)\n    \n    saved_count += 1\n\n# Create ZIP file\nzip_filename = os.path.join(OUTPUT_DIR, f\"best_model_predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip\")\n\nwith zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    # Add predictions\n    for test_file in os.listdir(pred_dir):\n        if test_file.endswith('.json'):\n            file_path = os.path.join(pred_dir, test_file)\n            zipf.write(file_path, arcname=f\"predictions/{test_file}\")\n    \n    # Add model comparison table\n    if os.path.exists(comparison_csv):\n        zipf.write(comparison_csv, arcname='model_comparison_table.csv')\n    \n    # Add feature dataset\n    feature_csv = os.path.join(OUTPUT_DIR, 'hybrid_features_dataset.csv')\n    if os.path.exists(feature_csv):\n        zipf.write(feature_csv, arcname='hybrid_features_dataset.csv')\n    \n    # Add feature descriptions\n    feature_desc = os.path.join(OUTPUT_DIR, 'feature_descriptions.csv')\n    if os.path.exists(feature_desc):\n        zipf.write(feature_desc, arcname='feature_descriptions.csv')\n    \n    # Add validation metrics\n    val_metrics_file = os.path.join(OUTPUT_DIR, 'validation_metrics.csv')\n    if os.path.exists(val_metrics_file):\n        zipf.write(val_metrics_file, arcname='validation_metrics.csv')\n    \n    # Add ablation study\n    ablation_file = os.path.join(OUTPUT_DIR, 'ablation_study.csv')\n    if os.path.exists(ablation_file):\n        zipf.write(ablation_file, arcname='ablation_study.csv')\n\nzip_size_mb = os.path.getsize(zip_filename) / (1024 * 1024)\n\nprint(\"=\"*80)\nprint(\"EXPORT COMPLETE\")\nprint(\"=\"*80)\nprint(f\"Best Model: {best_model_name}\")\nprint(f\"Predictions: {saved_count} files\")\nprint(f\"ZIP File: {zip_filename}\")\nprint(f\"Size: {zip_size_mb:.2f} MB\")\nprint(\"=\"*80)\nprint(\"\\nContents:\")\nprint(f\"  âœ“ {saved_count} prediction JSON files\")\nprint(f\"  âœ“ Model comparison table\")\nprint(f\"  âœ“ Feature dataset\")\nprint(f\"  âœ“ Feature descriptions\")\nprint(f\"  âœ“ Validation metrics\")\nprint(f\"  âœ“ Ablation study\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T17:46:11.705846Z","iopub.execute_input":"2026-01-28T17:46:11.706475Z","iopub.status.idle":"2026-01-28T17:46:12.446301Z","shell.execute_reply.started":"2026-01-28T17:46:11.706455Z","shell.execute_reply":"2026-01-28T17:46:12.445754Z"}},"outputs":[{"name":"stdout","text":"\nExporting predictions for BEST model: CV Only (Baseline)\n\n================================================================================\nEXPORT COMPLETE\n================================================================================\nBest Model: CV Only (Baseline)\nPredictions: 600 files\nZIP File: /kaggle/working/best_model_predictions_20260128_174611.zip\nSize: 3.93 MB\n================================================================================\n\nContents:\n  âœ“ 600 prediction JSON files\n  âœ“ Model comparison table\n  âœ“ Feature dataset\n  âœ“ Feature descriptions\n  âœ“ Validation metrics\n  âœ“ Ablation study\n================================================================================\n","output_type":"stream"}],"execution_count":23},{"id":"79e0ff7c","cell_type":"markdown","source":"## 18. Export Best Model Predictions\n\nCreate ZIP archive with predictions and evaluation metrics.","metadata":{}},{"id":"43517818-ccfe-4fed-be71-747bc2adc9ab","cell_type":"code","source":"from datetime import datetime\nimport zipfile\n\n# Export BEST model predictions to ZIP\nprint(f\"\\n{'='*80}\")\nprint(f\"CREATING ZIP ARCHIVE FOR BEST MODEL: {best_model_name}\")\nprint(f\"{'='*80}\\n\")\n\n# Get predictions for best model\nbest_predictions = all_model_predictions[best_model_name]\n\n# Create predictions directory\npred_dir = os.path.join(OUTPUT_DIR, \"predictions\")\nos.makedirs(pred_dir, exist_ok=True)\n\n# Save JSON files\nsaved_count = 0\nfor test_file, pred_data in best_predictions.items():\n    output_data = {\n        'image_file': pred_data['image_file'],\n        'model': best_model_name,\n        'data_points': pred_data['predictions']\n    }\n    \n    output_path = os.path.join(pred_dir, test_file)\n    with open(output_path, 'w') as f:\n        json.dump(output_data, f, indent=2)\n    \n    saved_count += 1\n\nprint(f\"âœ“ Saved {saved_count} prediction JSON files\")\n\n# Create ZIP file\nzip_filename = os.path.join(OUTPUT_DIR, f\"cv_ml_hybrid_predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip\")\n\nwith zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    # Add predictions\n    for test_file in os.listdir(pred_dir):\n        if test_file.endswith('.json'):\n            file_path = os.path.join(pred_dir, test_file)\n            zipf.write(file_path, arcname=f\"predictions/{test_file}\")\n    \n    # Add model comparison table\n    comparison_csv = os.path.join(OUTPUT_DIR, 'final_model_comparison_600samples.csv')\n    if os.path.exists(comparison_csv):\n        zipf.write(comparison_csv, arcname='model_comparison_table.csv')\n    \n    # Add improvement analysis\n    improvement_csv = os.path.join(OUTPUT_DIR, 'improvement_over_baseline_600samples.csv')\n    if os.path.exists(improvement_csv):\n        zipf.write(improvement_csv, arcname='improvement_analysis.csv')\n    \n    # Add feature dataset\n    feature_csv = os.path.join(OUTPUT_DIR, 'hybrid_features_dataset.csv')\n    if os.path.exists(feature_csv):\n        zipf.write(feature_csv, arcname='hybrid_features_dataset.csv')\n    \n    # Add feature descriptions\n    feature_desc = os.path.join(OUTPUT_DIR, 'feature_descriptions.csv')\n    if os.path.exists(feature_desc):\n        zipf.write(feature_desc, arcname='feature_descriptions.csv')\n    \n    # Add validation metrics\n    val_metrics_file = os.path.join(OUTPUT_DIR, 'validation_metrics.csv')\n    if os.path.exists(val_metrics_file):\n        zipf.write(val_metrics_file, arcname='validation_metrics.csv')\n    \n    # Add ablation study\n    ablation_file = os.path.join(OUTPUT_DIR, 'ablation_study.csv')\n    if os.path.exists(ablation_file):\n        zipf.write(ablation_file, arcname='ablation_study.csv')\n\nzip_size_mb = os.path.getsize(zip_filename) / (1024 * 1024)\n\nprint(f\"\\n{'='*80}\")\nprint(f\"ZIP ARCHIVE CREATED SUCCESSFULLY\")\nprint(f\"{'='*80}\")\nprint(f\"Best Model: {best_model_name}\")\nprint(f\"Predictions: {saved_count} files (600 test samples)\")\nprint(f\"ZIP File: {zip_filename}\")\nprint(f\"Size: {zip_size_mb:.2f} MB\")\nprint(f\"\\nArchive Contents:\")\nprint(f\"  âœ“ {saved_count} prediction JSON files\")\nprint(f\"  âœ“ Model comparison table (all approaches)\")\nprint(f\"  âœ“ Improvement analysis vs baseline\")\nprint(f\"  âœ“ Feature dataset (14 features)\")\nprint(f\"  âœ“ Feature descriptions\")\nprint(f\"  âœ“ Validation metrics\")\nprint(f\"  âœ“ Ablation study results\")\nprint(f\"{'='*80}\")\nprint(f\"\\nðŸŽ‰ All results exported! Ready for submission.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T17:46:12.447172Z","iopub.execute_input":"2026-01-28T17:46:12.447385Z","iopub.status.idle":"2026-01-28T17:46:13.156337Z","shell.execute_reply.started":"2026-01-28T17:46:12.447366Z","shell.execute_reply":"2026-01-28T17:46:13.155763Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nCREATING ZIP ARCHIVE FOR BEST MODEL: CV Only (Baseline)\n================================================================================\n\nâœ“ Saved 600 prediction JSON files\n\n================================================================================\nZIP ARCHIVE CREATED SUCCESSFULLY\n================================================================================\nBest Model: CV Only (Baseline)\nPredictions: 600 files (600 test samples)\nZIP File: /kaggle/working/cv_ml_hybrid_predictions_20260128_174612.zip\nSize: 3.93 MB\n\nArchive Contents:\n  âœ“ 600 prediction JSON files\n  âœ“ Model comparison table (all approaches)\n  âœ“ Improvement analysis vs baseline\n  âœ“ Feature dataset (14 features)\n  âœ“ Feature descriptions\n  âœ“ Validation metrics\n  âœ“ Ablation study results\n================================================================================\n\nðŸŽ‰ All results exported! Ready for submission.\n","output_type":"stream"}],"execution_count":24},{"id":"06a9a54d-c807-4fc3-b22b-de8aa109307f","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}